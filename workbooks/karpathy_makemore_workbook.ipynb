{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Workbook Overview\n",
        "\n",
        "This workbook guides you through coding the makemore project from scratch, following four key lectures from Andrej Karpathy's Makemore series.\n",
        "\n",
        "### Who Is This For?\n",
        "\n",
        "- Those familiar with Karpathyâ€™s \"Zero to Hero\" YouTube series.\n",
        "- Ideal for those who have coded along with the lectures and now want to test their understanding independently.\n",
        "\n",
        "### How to Use This Workbook\n",
        "\n",
        "- The workbook is divided into three main sections: **Coding Instructions**, **Coding Exercises**, and **Code Solutions**.\n",
        "- **Coding Instructions**: Provides a list of instructions for each part of the makemore project.\n",
        "- **Coding Exercises**: This is where you implement the code based on the provided instructions.\n",
        "- **Code Solutions**: Full code solutions are available here for reference or to check your work.\n",
        "- Use the Colab Table of Contents for easy navigation.\n",
        "\n",
        "### Purpose\n",
        "\n",
        "- Reinforce your understanding of NLP and deep learning concepts.\n",
        "- Progress from basic models to more complex architectures incrementally.\n",
        "- Focus on hands-on coding to internalize key mechanisms of language modeling.\n",
        "\n",
        "### Stages Overview and Lecture Mapping\n",
        "\n",
        "1. **Part 1 & 2 -> [Lecture 2](https://www.youtube.com/watch?v=PaCmpygFfXo):** Start with bigram language modeling and introduce a simple neural network with gradient descent.\n",
        "2. **Part 3 -> [Lecture 3](https://www.youtube.com/watch?v=TCH_1BHY58I):** Develop a multilayer perceptron (MLP) for more advanced language modeling.\n",
        "3. **Part 4 -> [Lecture 4](https://www.youtube.com/watch?v=P6sfmUTpUmc):** Modularize the code with custom layers and add Batch Normalization.\n",
        "4. **Part 5 -> [Lecture 6](https://www.youtube.com/watch?v=t3YJ5hKiMQ0):** Further modularize with an Embedding layer and a Sequential module, laying the groundwork for more complex architectures like [Lecture 7: GPT](https://www.youtube.com/watch?v=t3YJ5hKiMQ0).\n",
        "\n",
        "### Note\n",
        "\n",
        "Some advanced topics from the Makemore series are not included:\n",
        "\n",
        "- **Lecture 4:** Initialization strategies, gradient/activation diagnostics.\n",
        "- **Lecture 5:** Backprop Ninja (Note: Andrej's notebook for Lecture 5 is a stand-alone workbook and highly recommended. The insights on backpropagating through cross entropy loss and the gradient on logits are exceptional. [Watch video here](https://youtu.be/q8SA3rM6ckI?t=5568))\n",
        "- **Lecture 6:** WaveNet architecture.\n",
        "\n",
        "These topics were omitted to keep the workbook focused and manageable, emphasizing foundational concepts and code modularization."
      ],
      "metadata": {
        "id": "rn0bs1H28VlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Instructions"
      ],
      "metadata": {
        "id": "pslVQYnH8Ykj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Makemore (Building Character-Level Language Models)\n",
        "\n",
        "# Part 1: Bigram Language Modeling\n",
        "\n",
        "# 1. Download and load the \"names.txt\" dataset.\n",
        "#    - https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
        "# 2. Extract unique characters and create lookup dictionaries (`stoi` and `itos`).\n",
        "# 3. Count bigrams in the dataset and store them in a matrix.\n",
        "# 4. Normalize the bigram matrix to get a probability distribution.\n",
        "# 5. Sample new names from the bigram model using the probability matrix.\n",
        "# 6. Evaluate model quality by calculating negative log-likelihood (NLL).\n",
        "#   - NNL should be 2.45\n",
        "# 7. (Optional) Apply smoothing to the bigram model and re-evaluate.\n",
        "\n",
        "# Part 2: Simple Neural Network for Bigram Modeling with Gradient Descent\n",
        "\n",
        "# 1. Convert words into input-output bigram pairs.\n",
        "# 2. One-hot encode the input indices (`xs`).\n",
        "# 3. Initialize a basic neural network with a single linear layer.\n",
        "# 4. Train the model using gradient descent.\n",
        "#    - 100 steps. Loss should be close to 2.51\n",
        "# 5. Generate new names using the trained model.\n",
        "\n",
        "# Part 3: Multilayer Perceptron for Language Modeling\n",
        "\n",
        "# 1. Prepare the data by creating input-output pairs with context.\n",
        "#    - block_size. build_dataset(). shuffle words. train/val/test split.\n",
        "# 2. Initialize a multilayer perceptron (MLP) using `torch.randn()` for weights.\n",
        "# 3. Train the MLP with minibatches. 200k steps. Adjust the learning rate mid-training.\n",
        "# 4. Plot loss graph.\n",
        "# 5. Evaluate model performance. Loss: 2.14 <-> 2.18.\n",
        "# 6. Generate new samples.\n",
        "\n",
        "# Part 4: Modularizing with Custom Layers and Batch Normalization\n",
        "\n",
        "# 1. Define custom Linear, Tanh, and BatchNorm1d layers to modularize the network.\n",
        "# 2. Initialize the network with these custom layers, ensuring proper initialization.\n",
        "# 3. Train the model\n",
        "# 4. Set to evaluation mode, evaluate the models performance, and generate samples.\n",
        "\n",
        "\n",
        "# Part 5: Further Modularization with Embedding and Sequential Modules\n",
        "\n",
        "# 1. Introduce Embedding, Flatten, and Sequential layers to further modularize the code.\n",
        "# 2. Initialize the network using these layers.\n",
        "# 3. Train the model, evaluate, and generate samples.\n",
        "# 4. (Optional) Experiment with scaling the network and adjusting hyperparameters.\n"
      ],
      "metadata": {
        "id": "tp_KqZaUvh9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Exercises"
      ],
      "metadata": {
        "id": "xNqsb6JCDIad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Bigram Language Modeling"
      ],
      "metadata": {
        "id": "oV7TbmVMDIad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download and load the \"names.txt\" dataset.\n",
        "#    - https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
        "# 2. Extract unique characters and create lookup dictionaries (`stoi` and `itos`).\n",
        "# 3. Count bigrams in the dataset and store them in a matrix.\n",
        "# 4. Normalize the bigram matrix to get a probability distribution.\n",
        "# 5. Sample new names from the bigram model using the probability matrix.\n",
        "# 6. Evaluate model quality by calculating negative log-likelihood (NLL).\n",
        "# 7. (Optional) Apply smoothing to the bigram model and re-evaluate.\n",
        "\n",
        "# Follow the instructions and code the solution."
      ],
      "metadata": {
        "id": "oYvvd9KlDIad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Simple Neural Network"
      ],
      "metadata": {
        "id": "ZwEODkvyDIad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convert words into input-output bigram pairs.\n",
        "# 2. One-hot encode the input indices (`xs`).\n",
        "# 3. Initialize a basic neural network with a single linear layer.\n",
        "# 4. Train the model using gradient descent.\n",
        "#    - 100 steps. Loss should be close to 2.51\n",
        "# 5. Generate new names using the trained model.\n",
        "\n",
        "# Follow the instructions and code the solution."
      ],
      "metadata": {
        "id": "-drWvsECDIae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Multilayer Perceptron"
      ],
      "metadata": {
        "id": "vKKwTURjDIae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prepare the data by creating input-output pairs with context.\n",
        "#    - block_size. build_dataset(). shuffle words. train/val/test split.\n",
        "# 2. Initialize a multilayer perceptron (MLP) using `torch.randn()` for weights.\n",
        "# 3. Train the MLP with minibatches. 200k steps. Adjust the learning rate mid-training.\n",
        "# 4. Plot loss graph.\n",
        "# 5. Evaluate model performance. Loss: 2.14 <-> 2.18.\n",
        "# 6. Generate new samples.\n",
        "\n",
        "# Follow the instructions and code the solution."
      ],
      "metadata": {
        "id": "H2vANfx1DIae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Modularizing with Custom Layers and Batch Normalization"
      ],
      "metadata": {
        "id": "oDjh6k_lDIae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define custom Linear, Tanh, and BatchNorm1d layers to modularize the network.\n",
        "# 2. Initialize the network with these custom layers, ensuring proper initialization.\n",
        "# 3. Train the model\n",
        "# 4. Set to evaluation mode, evaluate the models performance, and generate samples.\n",
        "\n",
        "# Follow the instructions and code the solution."
      ],
      "metadata": {
        "id": "6fBUneOdDIae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Further Modularization"
      ],
      "metadata": {
        "id": "wpfRwM56DIae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Introduce Embedding, Flatten, and Sequential layers to further modularize the code.\n",
        "# 2. Initialize the network using these layers.\n",
        "# 3. Train the model, evaluate, and generate samples.\n",
        "# 4. (Optional) Experiment with scaling the network and adjusting hyperparameters.\n",
        "\n",
        "# Follow the instructions and code the solution."
      ],
      "metadata": {
        "id": "mUWEZ_lkDIae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Solutions"
      ],
      "metadata": {
        "id": "YPQ5OzAG8dvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Bigram Language Modeling"
      ],
      "metadata": {
        "id": "lu6gdLeE8f0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download and load the \"names.txt\" dataset.\n",
        "#    - https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
        "# 2. Extract unique characters and create lookup dictionaries (`stoi` and `itos`).\n",
        "# 3. Count bigrams in the dataset and store them in a matrix.\n",
        "# 4. Normalize the bigram matrix to get a probability distribution.\n",
        "# 5. Sample new names from the bigram model using the probability matrix.\n",
        "# 6. Evaluate model quality by calculating negative log-likelihood (NLL).\n",
        "#   - NNL should be 2.45\n",
        "# 7. (Optional) Apply smoothing to the bigram model and re-evaluate."
      ],
      "metadata": {
        "id": "wAnq0QjOAMUS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIBw6j7QGGd-",
        "outputId": "48632949-bc70-4289-99d5-8ac74d1a07c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-15 08:56:30--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: â€˜names.txtâ€™\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-08-15 08:56:30 (6.17 MB/s) - â€˜names.txtâ€™ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "chars = sorted(set(\"\".join(words)))\n",
        "stoi = {ch:i+1 for i, ch in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:ch for ch, i in stoi.items()}"
      ],
      "metadata": {
        "id": "kQEWTJVIGJDC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = {}\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs[:], chs[1:]):\n",
        "        bigram = (ch1, ch2)\n",
        "        b[bigram] = b.get(bigram, 0) + 1\n",
        "\n",
        "sorted(b.items(), key=lambda kv: -kv[1])[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx-lyeDLGkJU",
        "outputId": "12230ea1-da1d-41fd-9f79-78bbcd5d46c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('n', '.'), 6763), (('a', '.'), 6640), (('a', 'n'), 5438)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ApHhICc7H3-o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27, 27))\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs[:], chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        N[ix1, ix2] += 1\n",
        "\n",
        "P = N/N.sum(dim=1, keepdim=True)\n",
        "\n",
        "print(N[0])\n",
        "print(P[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wq1-hCGH9RI",
        "outputId": "2631bba4-2332-4f42-dc5a-3050fd903c77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0., 4410., 1306., 1542., 1690., 1531.,  417.,  669.,  874.,  591.,\n",
            "        2422., 2963., 1572., 2538., 1146.,  394.,  515.,   92., 1639., 2055.,\n",
            "        1308.,   78.,  376.,  307.,  134.,  535.,  929.])\n",
            "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
            "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
            "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "\n",
        "    out = []\n",
        "    ix = 0\n",
        "    while True:\n",
        "        ix = torch.multinomial(P[ix], num_samples=1, replacement=True).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix==0:\n",
        "            break\n",
        "\n",
        "    print(\"\".join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6sD0iyMIj_t",
        "outputId": "a5284f10-f1a3-41f0-e1ae-b7177fea3b1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chubelaieccarzajamerinya.\n",
            "anka.\n",
            "mokaraei.\n",
            "ron.\n",
            "a.\n",
            "naronon.\n",
            "jiamiaa.\n",
            "sel.\n",
            "sablahishi.\n",
            "jin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood = 0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs[:], chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        prob = P[ix1, ix2]\n",
        "        logprob = prob.log()\n",
        "        log_likelihood += logprob\n",
        "        n += 1\n",
        "\n",
        "print(f\"nnl: {-log_likelihood}\")\n",
        "print(f\"nnl(mean): {-log_likelihood/n}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8NcpqhUJR83",
        "outputId": "51e3635a-e604-4d9d-c46c-ba86909e7338"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnl: 559891.75\n",
            "nnl(mean): 2.454094171524048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. (Optional) Apply smoothing to the bigram model and re-evaluate.\n",
        "\n",
        "N = torch.zeros((27, 27))\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs[:], chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        N[ix1, ix2] += 1\n",
        "\n",
        "P = (N+1).float()/N.sum(dim=1, keepdim=True)\n",
        "\n",
        "log_likelihood = 0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs[:], chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        prob = P[ix1, ix2]\n",
        "        logprob = prob.log()\n",
        "        log_likelihood += logprob\n",
        "        n += 1\n",
        "\n",
        "print(f\"nnl: {-log_likelihood}\")\n",
        "print(f\"nnl(mean): {-log_likelihood/n}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWD7PxfGU0i4",
        "outputId": "2f34288b-76f7-4806-8ef8-022703b14f8b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnl: 559322.6875\n",
            "nnl(mean): 2.4515998363494873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Simple Neural Network"
      ],
      "metadata": {
        "id": "XLdEyq7KCVTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convert words into input-output bigram pairs.\n",
        "# 2. One-hot encode the input indices (`xs`).\n",
        "# 3. Initialize a basic neural network with a single linear layer.\n",
        "# 4. Train the model using gradient descent.\n",
        "#    - 100 steps. Loss should be close to 2.51\n",
        "# 5. Generate new names using the trained model.\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs[:], chs[1:]):\n",
        "        xs.append(stoi[ch1])\n",
        "        ys.append(stoi[ch2])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "\n",
        "n = len(xs)\n",
        "\n",
        "print(xs[:10])\n",
        "print(ys[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFEXeil2Cb5C",
        "outputId": "bd33d194-ee49-4494-be50-bb950aab4aec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  5, 13, 13,  1,  0, 15, 12,  9, 22])\n",
            "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "\n",
        "xenc[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKXnyxcQQQlH",
        "outputId": "9febebbb-e179-4257-a015-7575088e832c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27, 27), dtype=torch.float, requires_grad=True)"
      ],
      "metadata": {
        "id": "Gblhy_HKQ0lk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "\n",
        "    logits = xenc @ W\n",
        "    counts = torch.exp(logits)\n",
        "    probs = counts/counts.sum(dim=1, keepdim=True)\n",
        "    loss = -probs[torch.arange(n), ys].log().mean()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(loss.item())\n",
        "    W.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    W.data += -20 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzVsZVJARCGu",
        "outputId": "d56a9b74-22d7-4b7c-b08e-a30556bcf1c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5945448875427246\n",
            "2.890761375427246\n",
            "2.712392807006836\n",
            "2.634859323501587\n",
            "2.591519832611084\n",
            "2.5640904903411865\n",
            "2.5453431606292725\n",
            "2.5317258834838867\n",
            "2.5213875770568848\n",
            "2.5132882595062256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "\n",
        "    out = []\n",
        "    ix = 0\n",
        "\n",
        "    while True:\n",
        "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "        logits = xenc @ W\n",
        "        counts = torch.exp(logits)\n",
        "        probs = counts/counts.sum(dim=1, keepdim=True)\n",
        "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix ==0:\n",
        "            break\n",
        "    print(\"\".join(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ4_EZfXVjEh",
        "outputId": "88b1fc85-cd1f-4db9-ea8d-238e24a9ae09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gkoucana.\n",
            "ccam.\n",
            "ran.\n",
            "en.\n",
            "pzapldexkah.\n",
            "gi.\n",
            "esma.\n",
            "iecelvamycchgianin.\n",
            "da.\n",
            "sina.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Multilayer Perceptron"
      ],
      "metadata": {
        "id": "RoM6Ony5ChTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prepare the data by creating input-output pairs with context.\n",
        "#    - block_size. build_dataset(). shuffle words. train/val/test split.\n",
        "# 2. Initialize a multilayer perceptron (MLP) using `torch.randn()` for weights.\n",
        "# 3. Train the MLP with minibatches. 200k steps. Adjust the learning rate mid-training.\n",
        "# 4. Plot loss graph.\n",
        "# 5. Evaluate model performance. Loss: 2.14 <-> 2.18.\n",
        "# 6. Generate new samples.\n",
        "\n",
        "block_size = 3\n",
        "\n",
        "def build_dataset(words):\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for w in words:\n",
        "        context = [0] * block_size\n",
        "        for ch in w + '.':\n",
        "            ix = stoi[ch]\n",
        "            X.append(context)\n",
        "            Y.append(ix)\n",
        "            context = context[1:] + [ix]\n",
        "\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "FQAS6dqzCmer"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(words)\n",
        "\n",
        "n1 = int(len(words) * 0.8)\n",
        "n2 = int(len(words) * 0.9)\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xval, Yval = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])\n",
        "\n",
        "n = len(Xtr)\n",
        "\n",
        "print(len(Xtr), len(Xval), len(Xte))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dlk_OG1caty",
        "outputId": "1e4455da-f969-4a6d-ce38-58d747ba0c60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182540 22858 22748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn(27, 10)\n",
        "W1 = torch.randn(30, 100)\n",
        "b1 = torch.randn(100)\n",
        "W2 = torch.randn(100, 27)\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad=True\n",
        "\n",
        "print(f\"Number of parameters: {sum(p.nelement() for p in parameters)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQaI3JhwdCrG",
        "outputId": "68bda3ea-5be1-49af-b739-ffe59fd7eaaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 6097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "utzJfdwXgO32"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "max_steps = 200000\n",
        "print_steps = 10000\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "    ix = torch.randint(n, (batch_size, ))\n",
        "\n",
        "    Xb = Xtr[ix]\n",
        "    Yb = Ytr[ix]\n",
        "\n",
        "    emb = C[Xb]\n",
        "    h = torch.tanh(emb.view(Xb.shape[0], -1) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    if i % print_steps == 0:\n",
        "        print(f\"step: {i}, loss: {loss}\")\n",
        "\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    lr = 0.1 if i < 100000 else 0.01\n",
        "\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    stepi.append(i)\n",
        "    lossi.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMsSpPayd6QW",
        "outputId": "9d3e84d4-84a3-4cd9-e6e8-3bb8f4f7db4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss: 17.337295532226562\n",
            "step: 10000, loss: 2.1637043952941895\n",
            "step: 20000, loss: 2.631481409072876\n",
            "step: 30000, loss: 1.8925715684890747\n",
            "step: 40000, loss: 2.054985523223877\n",
            "step: 50000, loss: 2.0296449661254883\n",
            "step: 60000, loss: 3.0642309188842773\n",
            "step: 70000, loss: 2.4942116737365723\n",
            "step: 80000, loss: 2.2439377307891846\n",
            "step: 90000, loss: 1.793599009513855\n",
            "step: 100000, loss: 2.4949963092803955\n",
            "step: 110000, loss: 1.591558575630188\n",
            "step: 120000, loss: 2.485424041748047\n",
            "step: 130000, loss: 2.3732657432556152\n",
            "step: 140000, loss: 2.210106611251831\n",
            "step: 150000, loss: 2.1058366298675537\n",
            "step: 160000, loss: 2.1911792755126953\n",
            "step: 170000, loss: 2.0638315677642822\n",
            "step: 180000, loss: 1.8713964223861694\n",
            "step: 190000, loss: 2.404158115386963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "grt-Vjd5gf0s",
        "outputId": "b0084912-e5e4-4ba3-b272-e460d503215c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c0fed1f3d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "MEfZFlithExI",
        "outputId": "e288a07b-ab05-4b96-ef89-ff81d1da60a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c0fed118040>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr]\n",
        "h = torch.tanh(emb.view(Xtr.shape[0], -1) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(f\"Training loss: {loss}\")\n",
        "\n",
        "emb = C[Xval]\n",
        "h = torch.tanh(emb.view(Xval.shape[0], -1) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Yval)\n",
        "print(f\"Validation loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgV4BaOrjXG-",
        "outputId": "0f563936-8f09-41db-afd4-d88301ce817b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.1474788188934326\n",
            "Validation loss: 2.184391736984253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "        emb = C[torch.tensor([context])]\n",
        "        h = torch.tanh(emb.view(emb.shape[0], -1) @ W1 + b1)\n",
        "        logits = h @ W2 + b2\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
        "        out.append(itos[ix])\n",
        "        context = context[1:] + [ix]\n",
        "        if ix ==0:\n",
        "            break\n",
        "\n",
        "    print(\"\".join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMQf43AzkkQh",
        "outputId": "50594009-6982-4fdb-b165-f43ba15c5029"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shed.\n",
            "lynn.\n",
            "marri.\n",
            "menen.\n",
            "bra.\n",
            "ilardeorafalvingel.\n",
            "ori.\n",
            "colithaleisyn.\n",
            "milio.\n",
            "chn.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Modularizing with Custom Layers and Batch Normalization"
      ],
      "metadata": {
        "id": "mcN2q-mcCnIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define custom Linear, Tanh, and BatchNorm1d layers to modularize the network.\n",
        "# 2. Initialize the network with these custom layers, ensuring proper initialization.\n",
        "# 3. Train the model\n",
        "# 4. Set to evaluation mode, evaluate the models performance, and generate samples."
      ],
      "metadata": {
        "id": "jVu2W38hCq2S"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.rand(fan_in, fan_out) / fan_in**0.5\n",
        "        self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "class Tanh:\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return torch.tanh(x)\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "class BatchNorm1d:\n",
        "\n",
        "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "\n",
        "        self.running_mean = torch.zeros(dim)\n",
        "        self.running_var = torch.ones(dim)\n",
        "\n",
        "    def __call__(self, x):\n",
        "\n",
        "        if self.training:\n",
        "            if x.ndim==2:\n",
        "                dim = 0\n",
        "            elif x.ndim==3:\n",
        "                dim = (0,1)\n",
        "            xmean = x.mean(dim, keepdim=True)\n",
        "            xvar = x.var(dim, keepdim=True)\n",
        "        else:\n",
        "            xmean = self.running_mean\n",
        "            xvar = self.running_var\n",
        "\n",
        "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
        "        out = self.gamma * xhat + self.beta\n",
        "\n",
        "        if self.training:\n",
        "            with torch.no_grad():\n",
        "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n"
      ],
      "metadata": {
        "id": "c6DuCL7CpiRz"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 27\n",
        "n_embd = 10\n",
        "n_hidden = 100\n",
        "\n",
        "C = torch.randn((vocab_size, n_embd))\n",
        "\n",
        "layers = [\n",
        "    Linear(n_embd * block_size, n_hidden, bias=False),\n",
        "    BatchNorm1d(n_hidden),\n",
        "    Tanh(),\n",
        "    Linear(n_hidden, vocab_size)\n",
        "]\n",
        "\n",
        "with torch.no_grad():\n",
        "    layers[-1].weight *= 0.1 # make last layer less confident\n",
        "\n",
        "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad=True\n",
        "\n",
        "print(f\"Number of parameters: {sum(p.nelement() for p in parameters)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCvymWWrtTHE",
        "outputId": "f619c860-c1df-472f-dd8f-5e1b4186848c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 6197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "i1o_K3LkvNss"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "max_steps = 200000\n",
        "print_steps = 10000\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "    ix = torch.randint(n, (batch_size, ))\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "    emb = C[Xb]\n",
        "    x = emb.view(emb.shape[0], -1)\n",
        "    for layer in layers:\n",
        "        x = layer(x)\n",
        "    loss = F.cross_entropy(x, Yb)\n",
        "\n",
        "    if i % print_steps == 0:\n",
        "        print(f\"step: {i}, loss: {loss}\")\n",
        "\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    lr = 0.1 if i < 100000 else 0.01\n",
        "\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    stepi.append(i)\n",
        "    lossi.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2br-fSxWvRWQ",
        "outputId": "4858e8a5-aada-4e2b-d5e1-de3a1dda59b0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss: 3.3010454177856445\n",
            "step: 10000, loss: 2.092689037322998\n",
            "step: 20000, loss: 2.2485523223876953\n",
            "step: 30000, loss: 2.227540969848633\n",
            "step: 40000, loss: 2.535057544708252\n",
            "step: 50000, loss: 1.665380835533142\n",
            "step: 60000, loss: 1.7730025053024292\n",
            "step: 70000, loss: 2.359799385070801\n",
            "step: 80000, loss: 2.022021532058716\n",
            "step: 90000, loss: 2.2773194313049316\n",
            "step: 100000, loss: 1.7213916778564453\n",
            "step: 110000, loss: 2.433248281478882\n",
            "step: 120000, loss: 1.984510898590088\n",
            "step: 130000, loss: 2.594165325164795\n",
            "step: 140000, loss: 1.904783010482788\n",
            "step: 150000, loss: 1.9925380945205688\n",
            "step: 160000, loss: 1.9361546039581299\n",
            "step: 170000, loss: 1.8748481273651123\n",
            "step: 180000, loss: 2.1125032901763916\n",
            "step: 190000, loss: 2.886442184448242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "QiD_E6TUvtIb",
        "outputId": "014ab013-a57a-4dfe-fa76-e1991387db6b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c0fde5d99c0>]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWpklEQVR4nO3dd1xT5/4H8E8SkrBC2BsB996jSh21lg477B621u5a7K1tb39e29v2tvfe0r177VTbWq8dV2trW1us4gQHThwoMkWGgIRNQnJ+f5zkQGQj5ID5vF+vvITknPAcDnI+PM/3eY5CEAQBRERERDJRyt0AIiIicm4MI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWTGMEBERkaxc5G5Ae1gsFpw5cwY6nQ4KhULu5hAREVE7CIKAiooKhIaGQqlsuf+jV4SRM2fOICIiQu5mEBERUSfk5uYiPDy8xdd7RRjR6XQAxIPx8vKSuTVERETUHuXl5YiIiJCu4y3pFWHENjTj5eXFMEJERNTLtFViwQJWIiIikhXDCBEREcmKYYSIiIhkxTBCREREsmIYISIiIlkxjBAREZGsGEaIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLLqFTfK6y6fb8vA6XM1uGNiBAYH8wZ8REREcnDqnpFfDudjxc4s5JRUy90UIiIip+XUYcRFKd7SuN4iyNwSIiIi5+XUYUTFMEJERCQ7pw4japV4+GaLReaWEBEROS+nDiNSz4iZPSNERERyceowwpoRIiIi+Tl1GGHNCBERkfycOoy42GpGzKwZISIikotzhxH2jBAREcnOqcMIh2mIiIjk59RhRK20Te1lGCEiIpKLU4cRlYpTe4mIiOTm1GHEVjPCRc+IiIjk49RhxFYzYuIwDRERkWw6FEbi4+MxYcIE6HQ6BAYGYs6cOUhLS2tzv7KyMsTFxSEkJARarRYDBw7Er7/+2ulGd5WG5eAZRoiIiOTi0pGNt2zZgri4OEyYMAH19fV49tlnERsbi6NHj8LDw6PZfYxGI6644goEBgbihx9+QFhYGLKzs+Ht7d0V7b8gXA6eiIhIfh0KIxs2bLD7fMWKFQgMDERKSgqmTZvW7D7Lli1DaWkpdu7cCbVaDQCIiorqXGu7GGtGiIiI5HdBNSMGgwEA4Ovr2+I2P/30EyZPnoy4uDgEBQVh+PDheOWVV2A2m1vcp66uDuXl5XaP7sCaESIiIvl1OoxYLBYsWrQIMTExGD58eIvbZWRk4IcffoDZbMavv/6K559/Hm+99Rb+9a9/tbhPfHw89Hq99IiIiOhsM1sl1YxwmIaIiEg2nQ4jcXFxSE1NxerVq1vdzmKxIDAwEJ9++inGjRuH22+/Hc899xw+/vjjFvdZsmQJDAaD9MjNze1sM1vFFViJiIjk16GaEZuFCxdi/fr12Lp1K8LDw1vdNiQkBGq1GiqVSnpuyJAhKCgogNFohEajabKPVquFVqvtTNM6pOHeNKwZISIikkuHekYEQcDChQuxdu1abNq0CdHR0W3uExMTg/T0dFgaXfBPnDiBkJCQZoOII7FnhIiISH4dCiNxcXFYuXIlVq1aBZ1Oh4KCAhQUFKCmpkbaZt68eViyZIn0+YIFC1BaWoonnngCJ06cwC+//IJXXnkFcXFxXXcUneTCmhEiIiLZdWiYZunSpQCAGTNm2D2/fPlyzJ8/HwCQk5MDpbIh40REROD333/Hk08+iZEjRyIsLAxPPPEEFi9efGEt7wIu7BkhIiKSXYfCiCC0fdFOTExs8tzkyZORnJzckS/lECrWjBAREcnOqe9No1bZFj1jzwgREZFcnDqMqKzDSVwOnoiISD5OHUYaloNnGCEiIpKLU4eRhuXgWTNCREQkF6cOI6wZISIikp9ThxHWjBAREcnPqcMIa0aIiIjk59RhhDUjRERE8nPqMMKaESIiIvk5dRhhzQgREZH8nDqMsGaEiIhIfs4dRlS8Nw0REZHcnDuM8K69REREsnPqMGKrGTGzZoSIiEg2Th1GXDi1l4iISHbOHUY4tZeIiEh2Th1GVKwZISIikp1ThxEXa82IIAAWBhIiIiJZOHUYsfWMAKwbISIikotThxHbcvAA60aIiIjk4tRhpHHPCOtGiIiI5OHUYcRWMwJwrREiIiK5OHUYadQxwpoRIiIimTh1GFEoFFLdCGtGiIiI5OHUYQRotNYIh2mIiIhk4fRhxFY3wp4RIiIieTCMqGyrsLJmhIiISA4MI1wSnoiISFZOH0ZYM0JERCQvpw8jrBkhIiKSF8MIa0aIiIhk5fRhhMM0RERE8nL6MGIrYOUwDRERkTycPoyorDUjJoYRIiIiWTh9GGlYDp41I0RERHJw+jDCmhEiIiJ5OX0YYc0IERGRvJw+jNh6RlgzQkREJA+nDyNqlW3RM9aMEBERycHpwwhrRoiIiOTl9GGENSNERETyYhjhOiNERESycvoworKtM2JmzQgREZEcnD6M2IZp6tkzQkREJAunDyMq1owQERHJyunDiNpaM8KeESIiInk4fRix1Yxwai8REZE8nD6MNEztZQErERGRHJw+jKhYwEpERCQrpw8jtuXgGUaIiIjk4fRhhMvBExERycvpwwhrRoiIiOTFMMLl4ImIiGTFMCItB88wQkREJIcOhZH4+HhMmDABOp0OgYGBmDNnDtLS0lrdZ8WKFVAoFHYPV1fXC2p0V+JsGiIiInl1KIxs2bIFcXFxSE5ORkJCAkwmE2JjY1FVVdXqfl5eXsjPz5ce2dnZF9TorsSaESIiInm5dGTjDRs22H2+YsUKBAYGIiUlBdOmTWtxP4VCgeDg4M61sJvZwghrRoiIiORxQTUjBoMBAODr69vqdpWVlYiMjERERARuuOEGHDlypNXt6+rqUF5ebvfoLirrOiOsGSEiIpJHp8OIxWLBokWLEBMTg+HDh7e43aBBg7Bs2TKsW7cOK1euhMViwZQpU3D69OkW94mPj4der5ceERERnW1mm1xYM0JERCSrToeRuLg4pKamYvXq1a1uN3nyZMybNw+jR4/G9OnTsWbNGgQEBOCTTz5pcZ8lS5bAYDBIj9zc3M42s00q1owQERHJqkM1IzYLFy7E+vXrsXXrVoSHh3doX7VajTFjxiA9Pb3FbbRaLbRabWea1mFqFXtGiIiI5NShnhFBELBw4UKsXbsWmzZtQnR0dIe/oNlsxuHDhxESEtLhfbuDyrroGZeDJyIikkeHekbi4uKwatUqrFu3DjqdDgUFBQAAvV4PNzc3AMC8efMQFhaG+Ph4AMDLL7+MSy65BP3790dZWRneeOMNZGdn48EHH+ziQ+mchqm9DCNERERy6FAYWbp0KQBgxowZds8vX74c8+fPBwDk5ORAqWzocDl37hweeughFBQUwMfHB+PGjcPOnTsxdOjQC2t5F2lY9Iw1I0RERHLoUBgRhLZ7DxITE+0+f+edd/DOO+90qFGOxJoRIiIieTn9vWlYM0JERCQvpw8jrBkhIiKSF8MIa0aIiIhkxTDCmhEiIiJZOX0YYc0IERGRvJw+jLBmhIiISF4MIyrWjBAREcmJYYR37SUiIpKV04cRW82ImTUjREREsnD6MMKeESIiInkxjLBmhIiISFZOH0ZU7BkhIiKSldOHERdrzYggABYGEiIiIodjGLEO0wDsHSEiIpIDw4iycRhh3QgREZGjOX0YUSnZM0JERCQnpw8jtpoRgGuNEBERycHpw4hKqYDC2jnCnhEiIiLHc/owAjRe+Iw1I0RERI7GMIJGa41wmIaIiMjhGEbQUDdi5jANERGRwzGMoPGS8AwjREREjsYwAtaMEBERyYlhBKwZISIikhPDCFgzQkREJCeGETSuGeEwDRERkaMxjIDDNERERHJiGEFDASuHaYiIiByPYQQNNSOc2ktEROR4DCNgzQgREZGcGEbAmhEiIiI5MYyANSNERERyYhgBa0aIiIjkxDAC1owQERHJiWEErBkhIiKSE8MIWDNCREQkJ4YRsGaEiIhITgwjAFS2mhEza0aIiIgcjWEEDcM07BkhIiJyPIYRNAzTsGaEiIjI8RhGwJ4RIiIiOTGMoHHNCMMIERGRozGMoPHUXhawEhERORrDCDi1l4iISE4MI2i8HDzDCBERkaMxjIDLwRMREcmJYQSAWiV+G4xms8wtISIicj4MIwC83dQAgLJqk8wtISIicj4MIwB8PTQAgHPVRplbQkRE5HwYRgB4u4s9I6VV7BkhIiJyNIYRNPSMlLFnhIiIyOEYRgD4uIthpLSKYYSIiMjRGEYA+Fh7RurqLagxckYNERGRIzGMAPDQqKCxTu8t5VANERGRQ3UojMTHx2PChAnQ6XQIDAzEnDlzkJaW1u79V69eDYVCgTlz5nS0nd1KoVDAx0MsYj3HoRoiIiKH6lAY2bJlC+Li4pCcnIyEhASYTCbExsaiqqqqzX2zsrLw17/+FVOnTu10Y7uTrW6E03uJiIgcy6UjG2/YsMHu8xUrViAwMBApKSmYNm1ai/uZzWbMnTsXL730ErZt24aysrJONbY7sYiViIhIHhdUM2IwGAAAvr6+rW738ssvIzAwEA888EC73reurg7l5eV2j+4mLXzGMEJERORQnQ4jFosFixYtQkxMDIYPH97idtu3b8cXX3yBzz77rN3vHR8fD71eLz0iIiI628x2sy18do5LwhMRETlUp8NIXFwcUlNTsXr16ha3qaiowD333IPPPvsM/v7+7X7vJUuWwGAwSI/c3NzONrPduCQ8ERGRPDpUM2KzcOFCrF+/Hlu3bkV4eHiL2506dQpZWVm47rrrpOcsFov4hV1ckJaWhn79+jXZT6vVQqvVdqZpndZQwMqeESIiIkfqUBgRBAGPP/441q5di8TERERHR7e6/eDBg3H48GG75/7+97+joqIC7733nkOGX9qLU3uJiIjk0aEwEhcXh1WrVmHdunXQ6XQoKCgAAOj1eri5uQEA5s2bh7CwMMTHx8PV1bVJPYm3tzcAtFpnIgfOpiEiIpJHh8LI0qVLAQAzZsywe3758uWYP38+ACAnJwdKZe9b2JU3yyMiIpJHh4dp2pKYmNjq6ytWrOjIl3QYqWeEYYSIiMihel8XRjex3Syv1sSb5RERETkSw4iVh0YFtUoBgNN7iYiIHIlhxEqhULCIlYiISAYMI41w4TMiIiLHYxhphEvCExEROR7DSCO8WR4REZHjMYw00rAkPMMIERGRozCMNCKFEfaMEBEROQzDSCO2tUZKWTNCRETkMAwjjfhab5bHJeGJiIgch2GkEW/rME1JJcMIERGRozCMNOLLAlYiIiKHYxhpxDa1t6TK2K6bAhIREdGFYxhpxM9TDCPGeguqebM8IiIih2AYacRd4wJXtfgt4f1piIiIHINh5Dx+HloA4lANERERdT+GkfPY6kZKq+pkbgkREZFzYBg5j1TEyum9REREDsEwch4/qWeEYYSIiMgRGEbO48swQkRE5FAMI+fxabTWCBEREXU/hpHzcJiGiIjIsRhGzuPLnhEiIiKHYhg5j20VVk7tJSIicgyGkfP4Whc9K+XUXiIiIodgGDmPbZimymhGrYn3pyEiIupuDCPn8XJ1gVqlAMAiViIiIkdgGDmPQqGAjztn1BARETkKw0gzuPAZERGR4zCMNKNhRg3DCBERUXdjGGmGbUYN1xohIiLqfgwjzWhYhZVrjRAREXU3hpFmsICViIjIcRhGmuFrrRkp4cJnRERE3Y5hpBm8WR4REZHjMIw0g1N7iYiIHIdhpBl+vHMvERGRwzCMNMPWM2KoMcFktsjcGiIioosbw0gzvN01UIq3p0Fhea28jSEiIrrIMYw0Q6VUYGS4NwBg28lieRtDRER0kWMYacGsIYEAgI1HC2VuCRER0cWNYaQFs4YGAQC2pxejxmiWuTVEREQXL4aRFgwK0iHcxw119RZsT+dQDRERUXdhGGmBQqHArCFi7wiHaoiIiLoPw0grrrAO1fx5vBAWiyBza4iIiC5ODCOtmBjtC52rC4orjdifWyZ3c4iIiC5KDCOtUKuUuLS/PwBgT1apzK0hIiK6ODGMtGFEuB4AcORMucwtISIiujgxjLRhWKg1jOQZZG4JERHRxYlhpA3DQr0AABnFVaisq5e5NURERBcfhpE2+HtqEaJ3BQAcy+dQDRERUVdjGGkHW+9IKodqiIiIuhzDSDvY6kZS89gzQkRE1NUYRtpheJhtRg17RoiIiLpah8JIfHw8JkyYAJ1Oh8DAQMyZMwdpaWmt7rNmzRqMHz8e3t7e8PDwwOjRo/H1119fUKMdzTZMc7KoErUm3jSPiIioK3UojGzZsgVxcXFITk5GQkICTCYTYmNjUVVV1eI+vr6+eO6555CUlIRDhw7hvvvuw3333Yfff//9ghvvKCF6V/h6aGC2CEgrqJC7OURERBcVhSAInb7pytmzZxEYGIgtW7Zg2rRp7d5v7NixmD17Nv75z3+2a/vy8nLo9XoYDAZ4eXl1trkX5J4vdmHbyWK8cuMI3DWpjyxtICIi6k3ae/2+oJoRg0GsofD19W3X9oIg4M8//0RaWlqHwktPYCti3ctl4YmIiLpUp8OIxWLBokWLEBMTg+HDh7e6rcFggKenJzQaDWbPno0PPvgAV1xxRYvb19XVoby83O4ht1lDAgEA6w/lo8BQK3NriIiILh6dDiNxcXFITU3F6tWr29xWp9PhwIED2LNnD/7973/jqaeeQmJiYovbx8fHQ6/XS4+IiIjONrPLjI/yxcRoXxjNFny6NUPu5hAREV00OlUzsnDhQqxbtw5bt25FdHR0h7/ogw8+iNzc3BaLWOvq6lBXVyd9Xl5ejoiICFlrRgBg64mzmLdsN1zVSmxfPBP+nlrZ2kJERNTTdUvNiCAIWLhwIdauXYtNmzZ1KogA4hBP47BxPq1WCy8vL7tHTzB1gD9GhetRa7Jg2fZMuZtDRER0UehQGImLi8PKlSuxatUq6HQ6FBQUoKCgADU1NdI28+bNw5IlS6TP4+PjkZCQgIyMDBw7dgxvvfUWvv76a9x9991ddxQOolAoEHdZfwDAf3fnwGzp9EQkIiIisnLpyMZLly4FAMyYMcPu+eXLl2P+/PkAgJycHCiVDRmnqqoKjz32GE6fPg03NzcMHjwYK1euxO23335hLZfJzMGB0GldcK7ahCNnDBgZ7o1TZyvx7Z5cPD6zP3SuarmbSERE1Ktc0DojjtIT1hlp7KGv9iLhaCGeuXIQ4i7rj9s/ScKuzFI8e81gPDytn9zNIyIi6hEcss6Is5o6wB8AsP1kMQoMtdhtXXvkZGGlnM0iIiLqlRhGOuHS/mIYSck+hx9ScmHrW8osbnlZfCIiImoew0gnRPt7IMzbDUazBf9JPCU9n8EwQkRE1GEMI52gUCgQ098PAFBtNEOpEJ8vrTKirNooY8uIiIh6H4aRTrp0QID08ZR+/gj2cgXA3hEiIqKOYhjppJh+ftLH148KRbS/BwAg8yzDCBERUUcwjHSSn6cWd07sg9ER3rh6RDD6BohhJKOYM2qIiIg6okOLnpG9+JtGSB/bekYy2DNCRETUIewZ6SL9AjwBcHovERFRRzGMdBGpZqS4Chbes4aIiKjdGEa6SLiPG9QqBerqLThjqGl7ByIiIgLAMNJlXFRK9PF1B8C6ESIioo5gGOlCfVk3QkRE1GEMI12or7VuZMuJszh1thK94IbIREREsuPU3i40OEQHANh0vAibjhehj687rh4RjJvGhGNQsE7m1hEREfVM7BnpQrNHhOLvs4dgSj8/aFRK5JRW45MtGbj+w+04XlAud/OIiIh6JIXQC8YSysvLodfrYTAY4OXlJXdz2qXaWI/EtLP4T2I6UvPKcc8lkfjnnOFyN4uIiMhh2nv9Zs9IN3HXuOCaESFYfNVgAMC6A3moNZllbhUREVHPwzDSzWL6+SPM2w3ltfX4/UiB3M0hIiLqcRhGuplSqcAt48IBAN/tzZW5NURERD0Pw4gD3Do+HAoFsCO9BM98fxC3LN2Jb/fkyN0sIiKiHoFTex0g3McdMf38sT29GN+nnAYAHM4zIKa/P8J93GVuHRERkbzYM+Igz80egmtHhmDBjH4YHeGNunoLXtuQJneziIiIZMepvTI4csaAaz/YDkEA/rdgMsZF+srdJCIioi7X3us3h2lkMCxUj9vHR2D1nlzM+2I3tGoVfD00eOXGEZgYzWBCRETOhcM0Mnk6dhC83dWoMppRWmVEelEl7v58F9buPy1304iIiByKPSMyCdBpkfDkdOSV1cBVrcT7f57Er4cL8OS3B6FSKnH9qFC5m0hEROQQ7BmRUYBOi9ER3hgc7IUP7xyLOyf2AQB8z/VIiIjIiTCM9BBKpQL3xUQBAPZklbZr6fi8shoYqk3d3DIiIqLuxTDSgwwI9ESATotakwX7cs61uu2Zshpc/lYi5i3f7aDWERERdQ+GkR5EoVDg0v7+AIAd6cWtbrsv5xxqTRYczC1DXlmNI5pHRETULRhGepgYaxjZnl7S6nYnCiqkj3e2EVyIiIh6MoaRHsbWM3L4dFmr9SBphQ1hJOlU68GFiIioJ2MY6WGC9a7oH+gJiwAkZbTc43GisFL6eOepEvSChXSJiIiaxTDSA10qDdU0H0ZqTWZklVQBAFRKBQrKa5FZXOWw9hEREXUlhpEeyFY3svVEcbM9HulFlRAEwNdDg/GRPgDE3hEiIqLeiGGkB5rSzw8alRI5pdVIL6ps8nqatXh1YJCnFFxYN0JERL0Vw0gP5KF1weR+fgCAjceKmrx+wlq8OihIhynW7ZIySmCxsG6EiIh6H4aRHmrWkEAAwJ/HCpu8ZptJMzBYh5Hh3nDXqFBaZbSbYQMAgiDgi+2Z+E9iOrJLWFNCREQ9E8NIDzVzSBAAcXGz0iqj3Wu2NUYGBemgcVFiQpQvgKZ1I19sz8Q/1x/F6xvSMP2NRNz9+S5U1IrThYsqavHI13vxy6H87j4UIiKiVjGM9FBh3m4YEuIFiwBsPt4wVFNea8IZQy0AYECQDgAQ018cqmm8+NmB3DK8tuE4AGBYqBeUCnF2ztLEUwCA135Lw+9HChH/2zFOCyYiIlkxjPRgtqGajY2Gak5ah2JC9K7Qu6kBAFP6iUWsuzJLUW+2wFBjwsJV+2AyC7hmRDDWP34pPr57HACxt2Tz8SKs2X8aAHD6XI00LTjjbCV+OniGtSdERORQDCM92OXWoZotJ84iOaMEtSYzvk7KBgAMtPaKAMCQEC/o3dSorKvH4TwDPtuagdPnahDh64ZXbx4JhUKBK4YGYUKUD+rqLXjoq71o3Bmy5cRZCIKAB7/ai7/8dz+W7ch06HESEZFzYxjpwUaG6TE0xAvVRjPu+DQZ09/YjB8PnAEA3DgmTNpOpVTgkr5i3cgfRwvxVVIWAOC5a4bCy1XsPVEoFPjb1UMAAPUWAWqVAndN6gMA2HriLJIzSpFxVuwhefOPNOSUVCPjbCXuX7EHq3fnOOR4iYjIOTGM9GBKpQKrH7lECg2F5XUI0Gnx5f0TMadRGAEahmo+25qB8tp69A3wQOzQILttxkX64JoRwQCAuy+JxLzJkQDEacFf7swSv6YCqDVZ8MjKFNzw4Q5sOl6EDzald+dhEhGRk3ORuwHUOi9XNV65cQRuGBWK5IxS3DM5Er4emibb2dYbqbfWezw6vR+USkWT7d64ZRRmjwjFFUODoFYpEOSlRWF5HTYcKQAAvHfHGDzzw0Ecyy+X9skrq0FFrQk6ay8LERFRV2LPSC8xqa8fnpg1oNkgAgD9Az0RoNMCAIK9XDFndFiz23loXTB7ZAg0LkooFApMHxggvTYkxAvXjgzBC9cOg0alxNxJfaT3PNnMSrAX4mRhBV5Yl4qzFXVd+r5ERNT7MIxcJBQKhTT75pHpfaFxad+pnT4wUPr4rokRUCjEWpIjL1+Jf984AoODxULZk+ctqHYhTGYLFnyzD18lZWPFThbLEhE5Ow7TXESemz0Uc0aHYWK0b7v3ubS/P3RaFygUwPWNelPUKjHMDAzSYdvJYqQVdF3PyFdJ2dI9dw6dNnTZ+xIRUe/EMHIR8dS6YFJfvw7to3dX48eFMXBRKqR1SxobGOQJADhZ1PGekVqTGYlpZzGlv580q6e4sg7vbjwhbXPotAGCIEChaFrf0priyjoczjNgxsCADu9LREQ9C4dpCP0CPBHp59Hsa7b1TGx3Cm6vjLOVuPE/O/HoyhTEfbNPev7N39NQUVuPoSFe0KiUMNSYkFNa3aH3rjdbcPfnu3Df8j1YZ53qTEREvRfDCLXKtuR8UUUdyqqNbWwt2nS8ENd9sF2akbPtZDFS8ww4WViB7/bmAgBevmEYhoSI793RoZovk7Jx3BqOvtieyeXsiYh6OYYRapWn1gVh3m4AgBOF9nUjBYbaJkHgQG4ZHvtmH6qMZkyK9sXlg8UC2U+2ZuCtP07AIgBXDgvC+ChfjAjXAwAO57U/jBSV1+LdhIZhnsN5BuzLKevMobWbxSKgsLy2W78GEZEzYxihNg2yzqhJazSj5u0/0nBJ/J947sdU6bnc0mo8+OUe1JosuGxQAL55cBKejh0EAPjl0BlsOFIApQL4q/W5kWHeAIBDp8va3Zb4346joq4eoyK8ccu4cADACuuCbd1l9Z5cTHrlT3y7hyvREhF1B4YRapOtbsQ2vffng2fwvnVV1lW7crDxaCGKymsxf/luFFcaMSTECx/cNRYuKiWGhnph2sAA2O69d+OYcGnox9YzkppXDotFQHpRhTTLpjl5ZTVYuz8PAPDPG4bhvpgoAMBvh/O7tedih/VuyD+knG7X9iazBWbebJCIqN06FEbi4+MxYcIE6HQ6BAYGYs6cOUhLS2t1n88++wxTp06Fj48PfHx8MGvWLOzevfuCGk2OZZtRk1ZQgaRTJXjmh4MAgGh/sej1b2sO445Pk3HqbBVC9K5YNn88PLUNE7UendYXAKBWKbBo1gDp+QGBntC6KFFZV49v9+biqne34Yp3tuD5H1NRXmtq0o51B8QgMinaFyPDvTEsVI+J0b6otwh4+48TTYaMBEFASeWFL6qWVSLes2dfThkMNU3b1diZshqM+2cCHvl6L2tZiIjaqUNhZMuWLYiLi0NycjISEhJgMpkQGxuLqqqqFvdJTEzEnXfeic2bNyMpKQkRERGIjY1FXl7eBTeeHMPWM7IrsxR3fpaMWpMFMwYF4Je/XIr+gZ4orqxDRnEVwrzd8N0jkxGid7Pbf3I/P7xxy0h8Nm88InzdpeddVEoMC/UCADy79jDqLQIEAfg6ORtXvL0FOSX2s2zW7RdnzjS+L8/jM/tDoQC+3ZuLjzbb30Pn6e8PYvy/N0rPl1YZ8dR3B/D5tox2H7sgCMi2tsNsEbD9ZHGr2/908AzKa+ux8VgRdp4qaffX6azNx4uw6Xhht38dIqLu1KEwsmHDBsyfPx/Dhg3DqFGjsGLFCuTk5CAlJaXFfb755hs89thjGD16NAYPHozPP/8cFosFf/755wU3nhyjv7UHAwA0KiVuGReO9+8cA3eNC966dRTcNSpE+bnj20cusQsbNgqFAreOj8CMQYFNXhsZ7g0AEARgaIgXls0fjyg/dxSW1+Hp7w9Iwx3H8suRVlgBjUqJa4aHSPtPHRCAf1w3DADw5h8nsDI5GwCw/tAZrNmXB0EA3vg9DfG/HsON/9mBNfvy8PqGNJjMlnYde0mVEZV19dLniWlFrW7/h/UePwDw3saT3do7cq7KiIe+2ouHv0rpkh4gIiK5XNCiZwaDOAvC17f9K35WV1fDZDK1uk9dXR3q6hp+uZaXl7e4LXU/V7UKn84bj+ySKsweEQI/T6302qgIb+xYPBM6Vxe4qDpegjSmjzdW7AR8PTT4dN44hPu4Y0CgDle9uxV7ss7hs20ZeHR6P/xoHaK5bHAA9O72i7PdOyUKRRW1+GjzKfz9x1Qcyy/Hb6liKBgVrsfB0wZ8srWhN8RotiCzuErq8QGAGqMZH24+iZmDgzAu0kd6PrvEvtcv8cRZWCxCszchLCqvxf7cMgBiaNudVYqkjBLpjspdbX/uOenGiCnZ5xA7LLhbvg4RUXfrdAGrxWLBokWLEBMTg+HDh7d7v8WLFyM0NBSzZs1qcZv4+Hjo9XrpERER0dlmUheZPjAA8yZH2QURGx8PTaeCCADMHhGCF64dim8fvgThPmKvSoSvO1609na8/ccJvP1HWsMQTQs3APxr7CD85XKxHuWbXTkorTJicLAO3z86BX+Z2R8AMC7SB4OsAeT4eYu4fb4tAx9tPoW5nydjd2ap9HxWsThEMz7SB+4aFc5W1GF/bhk+2XIK7208iTNlNdK2CccKIQjA6Ahv3D5B/Jm9kN6RE4UVSM0ztLh/SvY56eO9jT4mIuptOh1G4uLikJqaitWrV7d7n1dffRWrV6/G2rVr4erq2uJ2S5YsgcFgkB65ubmdbSb1cC4qJe6/NFqaYWNz6/hwzBoSBKPZgvc3paOgvBY6VxdcNrjpUA8gDgU9dcVAfHrPOHhqXaBxUeLNW0dB46LEU7GDsPNvM/H9I5MxNtIbAJBW0NDbVldvxlfW4Z1akwX3r9gjTTe29YwMDNZhSj9xqf07P01G/G/H8c7GE5j6+mbEfbMPheW1+OOIWLsROywIC2b0g0alxK7MUqzc1fEpwftzzuGa97bh2g+2Y8abifh4yylYzpuhsy+7TPp4b1YpiIh6q04N0yxcuBDr16/H1q1bER4e3q593nzzTbz66qvYuHEjRo4c2eq2Wq0WWm3Tv8DJeSgUCnx41xh8uycXqXkGZJVU4eax4XBVq1rdL3ZYMLb9ny+qTWZpsTYACLV+PEha3r5hCvH6g/k4W1GHIC8tov09kJxRioe+2osdi2ciy1q8GuXnjiEhXth4rAhGswXBXq6I9HPHrsxS/HI4H7syS2GoEVeojR0ajFBvNzwdOxDxvx3HSz8dweBgHSZEtW84s6quHou+PSANwWSXVOPV347D202NOyb2ASAuiX+w0fosqXnlqDWZ2/z+EBH1RB0KI4Ig4PHHH8fatWuRmJiI6Ojodu33+uuv49///jd+//13jB8/vlMNJefjqlbh3ilRHd7Px0MDnxZeGxQszt5JKxR7RgRBwBfbMwEA8yZH4d4pUYh5dRMKy+tw8HSZNK030s8Dl/b3R0pWKfr4uuOR6f3goXXBsfxyPPntAWnYp1+AB/oHilOhH57WF4fyDPjlUD4WrNyHX5+4FIE6sUcwNc8Ab3e1NDTV2Es/H0F2STVC9a7432NT8OXObHy85RTe+/Mk5owJg6taheMFFag2mqHTusDVOnx0OM/Q7sBDRNSTdGiYJi4uDitXrsSqVaug0+lQUFCAgoIC1NQ0jJvPmzcPS5YskT5/7bXX8Pzzz2PZsmWIioqS9qms7Lpb0hO112DrarK5pTWorKtHckYpjuaXw1WtxF0T+8BT64KpA8SC08S0s8gsFsNIlJ8HPLQuePeOMXgqdhA8rOuoDAnxwprHpuCG0aEAgJvHNfQUKhQKvHHLSAwMEqc/r0wWh2vSiyow56MduHnpTtSazHbtS84owXd7T0OhAN6+fTRC9G5YNGsAQvWuyDfU4uskcThpf45YIzK6jzfGWwtu9zhoqEYQBFQ0sw4MEVFndSiMLF26FAaDATNmzEBISIj0+Pbbb6VtcnJykJ+fb7eP0WjELbfcYrfPm2++2XVHQdROPh4aBOrEIcAThRX40rqU/E1jw+HjoQEgFusC4pohFbXitN4+zUxZtnHXuOC9O8Zg17OXY8H0fk1ee2yGWEC77kAeBEHAd3tPo94ioLC8TrpxoM3Go2LdyU1jwnFJX7FGxVWtwqIrBgIAPkpMR3mtSbofz9g+PtLsn5QsxxSxfpWUjRH/+ANr97dvRdp9Oed4bx8ialWHh2nakpiYaPd5VlZWR74EUbcbFKxDUUUdtp0oRsIx8eJ/7+Qo6XVbGLEtdhbs5Qo3Tdu1GEFezRdlXzE0CG5qFbJLqpGSfU5a0h4APtmSgTsn9oHaOhspKUNcKG36oAC797hpTBg+3ZqB9KJKLFiZgsyzYo/N2EgfeLuJU51Tcs7ZTTvemV6MCF93u7VfBEGAQqGQPk48cRZh3m5205wBsSYlMe0sxvTxtptBZbEI+My6aNx7G0/ihlFhzU5ztknJPoebl+7EmD7eWPtYTIvbEZFz471pyOnYilg/2XoKZouA8ZE+0s0AASDQy1UazgGAKP+We0Xaw0PrgthhQQCA59am4mxFHXw9NPD31CCvrAY/HxSnLZdVG3E0X6xluaSvfe2Hi0qJf80ZDneNCjvSS3DGIPY0jI7wxtBQL7ipVSirNkk3M/wh5TTu+nwX7vo8GcZ6cYG39zaexOiXE/D5tgyYLQJeXn8U9y3fgzs/TbYbLqqrNyNu1T48+NVePLc21a4duzJLcfqcOCybVVKNzW0sArf+kHhs+3PKUFpl7Pg3j4icAsMIOR1b8Kg2ihfguZf0abJN456JKD+PC/6atpoSW1i4YXQo7osRC8CXJorTdpMzSiEI4oq3tkLXxi7p64c1j02RhowGBemgd1NDrVJK4eXp7w7iWH45Xlwnhojc0hp8uzcX6UWVeH/TSRhqTPjXL8cw7fXNWL4jC4C4yqztvj81RjMe/HIvfrdOU9528qzdarX/2ycOzbiqxV8dy3ZktnjMgiBI050BYHdm9y+PT0S9E8MIOZ3B1hk1AODtrsbVjZaXt7EN1QDiTJoLNXVAAHytNSkAcPPYcNwzORI6rQtOFlXi19R8JFuHaCZba0VaavtPC2Pw2Ix++OechsUGX75hOPw9NTiaX47rP9yOKqMZXq7iKOxHm9Lxr1+OwmwRMCDQExoXJfLKauCiVOAya+hatj0LFouAJ1bvx7aTxXBTq+CpdUGV0YyD1lVlq431+O2wWA/22s0joVIqsCO9BMcLml8h+Vh+BfIaLQqXnMG1UIioeQwj5HQGBHnCVuZwSwtrl4yP9IW7tU4kyu/ChmkAQK1SYvYIMfQMDtZhWKgXvFzVuP9SsXfk7YQT2JEu3oRvcr+WwwgAeLtr8H9XDcbE6IahnAhfd3x+7wS4qpUwmQV4al2w5rEYhOhdUVBei8S0s1ApFVh69zj8+FgMbh0Xjq/un4h37xgDd40KaYUVeHz1fvxxtBAalRJfPTBRCmTbre3akFqAKqMZUX7uuH5UKK6yLj//xbaG3pGqunpp1dg/jopL8uusocgWtoiIzscwQk7HVa3CpGg/eGpdcPclkc1uo3FR4vGZAzAhygcxA7rm3jILZvRD7NAgvHjdMKmI9MGp0fB2VyPjbBVOFonT3S9ppWekNaMjvLF07jiMCNPjndtHo3+gJ+Iu6y+9fufECPQP9MTQUC+8cesoTOnvD72bGrdYpyP/ckjs9fj7tUMwIcoXMf3F496ZLoaIb/eIM39uGhsOhUIhBakfD+Qhr6wGZouAOz5NxrUfbMerG45LQzQLrW04XlCB0ioj9maV4h8/HUFVoxsQEpFzu6Ab5RH1Vsvvm4Cquvpm77Vjs2BGPyyY0a/F1zsq1NsNn86zX/RP56rGYzP64ZVfjwMQe00aD+d01GWDA+2WzL9tfARWJmejtMqIJy4f2Ow+906JwlfW9UuuGRGMe6wBLaa/GIr2555DwtFC7MoshVqlkNZSGRfpg8l9/ZCUUYKPE09hWKgXDueJN8/8ZIs440apAG4ZF441+/KQVliBXw6dwVsJJ1BWbYK/pwYLZw7o9LES0cWDPSPklFzVqlaDiCPNmxwlrX3S2V6RlmhclPhp4aXY+n+XIUDX/PH2C/DEX2b2x6whgYi/aaTUa9PH1x1h3m4wmQU8/d0BAMDcSZF2y+zbbk747Z5cvPF7GgDg0v4NPUnjo3zh56mVCmxf+vkoyqrFBdPW7s/r9E0EiejiwjBCJDNXtQqv3TIS4yN9MG9y88NGF0LjomzznjVPxQ7C5/dOgN66ZgkgriBr6x0pr62Hu0ZlN+wDiFOQJ0T5wGi2oKTKiCg/dyybPwHxN41AgE6L+2OiAACTrCGr3iJAo1JC46LEqbNVSM1rvviViJwLwwhRD3DZoED8sGAK+gZ4yt0UOzGNejkevDS6Se+KQqHA442GWpZcMwQaFyXunNgHe56bhausM5UmNSq2XXTFAFwxVFx3pfECcETkvFgzQkQturS/Pzy1LnDTqPDgtL7NbjN1gD8en9kfCgCx1pBxPj9PLf7vqkEoKq/Dw1P7YsuJs/jlUD5+OngGz14zGC4q/l1E5MwUQi8YtC0vL4der4fBYICXl1fbOxBRl8ktrYZWrWx2IbbOMpktmPjvjThXbcKK+yZgxqDAtnciol6nvddv/jlCRK2K8HXv0iACiOuuXDdKXJV2Q2pBl743EfU+DCNEJAvbSrO2+/EQkfNiGCEiWdjuEXSisAJmS48fLSaibsQwQkSyiPTzgKtaiVqTBdklVXI3h4hkxDBCRLJQKRUYECj2jqQVVMjcGiKSE8MIEclmsHWo5jjDCJFTYxghItnY6kbYM0Lk3BhGiEg2g4PFdQfSChlGiJwZwwgRycbWM5JVUoUao1nm1hCRXBhGiEg2ATot/Dw0EATgZFHrvSPltSbUmhhYiC5GDCNEJCtb78jx/JbDSFF5LS57IxE3/WcnesEdLHq1AkMtXlyXivSiSrmbQk6EYYSIZDWoHTNqPtmagZIqI47mlyOntNpRTXNKK5Oz8WVSNj7fliF3U8iJMIwQkaxs03vTCptfFr64sg7f7MqWPt+Tdc4h7XJWtuGy1kKfIAjYeaoYlXX1jmpWr3WisAIv/3wU5bUmuZvSozGMEJGshoSIM2oO5hpQ1czF7bNtGag1WaTP92aVOqxtzujUWXE13NPnalrcZu3+PNz12S68+tsxRzWr13r1t+NYtiMTX+3M6rL3zCurafb/Sm/GMEJEshoeqkdffw9U1tXjf/tO271WWmXEyiSxV+TOiX0AAHu6KIz8kHIat32chAJDbZe838Wg3tywNH++oabFewZtOl4EAEjOYDBsjcUiICVb7Mmz/Xuh0osqMf31zXjgyz1d8n49BcMIEclKqVTg3ilRAIAVO7JgsV4ASyrrMG/ZLlQZzRga4oVnrhwEQPzLvaSy7oK+ZkWtCS/9fAS7s0rxZVLWBb3XxST3XA1MZvH7bzILKKpoGtQEQcDuTDGEZJyt5JTsVmQUV8FQIw7P7M8t65Li66RTxai3CEjOKMWB3LILfr+egmGEiGR387hw6LQuyCiuwpaTZ5FdUoXbPklCal45/Dw0ePPWUfD10GBAoCcAYO8F/pW5encuKmrFbu6fDpyRAlBnbEjNx9TXN10UF4ZT582gaW6oJrukGkUVYhi0CMDxAvtan8OnDVi4ah8e/HIv4r7Z12U9Wb3RvpyGn9OyahMyiy/8hpBHG80668qhH7kxjBCR7Dy1LrhtQgQAYPEPhzDzrS04dbYKoXpXfPfoZAwNFetKxkf5AmhaN5JXVoO6+vb9hW6st+CL7Zl2+za+aHSEIAh4/fc05JbW4Ns9uZ16j9be++Wfj+Kxb1LafWwX6tRZ+zCS10wYsfWK2Bw50xBGckurcc+yXVh/KB8bjxXil8P5eHHdkXZ/fUEQkHG2Eql5Bum5erMF8b8ew+9HCprdp6zaeEFhsjvtP+/nal9Omd3nKdnn8MX2TJyrMrb7PY/lN3y/1x/Kv+Bewp6CYYSIeoR7J0dBoQCKKupgtgiYOsAf3y+Ygn4BntI2E6N9ANjPqEnJLsXU1zbhyW8PSM+dLKzAd3tyUW9uKHy1+engGRSU1yJQp8W1I0Ok5zpjX845ZFgLPve10lvz+5ECDHzuN2xIbf6C2pyfDp7Bsh2Z+PVwAX49nN+p9nXU+WHk9LmmM2p2WcOIxkW8fNjCSLWxHg99tRdl1SaMCNPjnzcMg0IBHM0vb7Mup7TKiH/8dAST4zdh5ltbcO0H25F0qgQAkHC0EJ9szcDff0xtMsyRcLQQY/6ZgPf+PNm5A+4i5bUm/Gv90Sbfv33ZZQCAaH8P8fPzwsni/x3CP9cfRcxrm/Cv9UfbDJ1miyD1RAV5aWE0W/Dt3q4NwXJhGCGiHqGPnzteuHYobhoThrWPTcHXD0xCmLeb3TbjI8WekdQ8g1Sr8EPKaVgE4NfDBUgvqoSx3oL5y/fg//53CIu+PWAXSOrNFnyy5RQA4L6YaNw6XuyN+eVQPkzNBJeDuWV4bu1hGKqbn5bZuDfkRFGFVB9wrsoofQwA/0s5DaPZgh9SWr5wHDljwINf7sV3e3NRWmXEyz8flV77Kim7xf3ao9ZkxtmKhr+giyvrcNdnyfjyvG5+W7Dqbx0Oa26YZneWGBLmjA4FIIYNAPj72lQcL6iAv6cWn84bh3smR2F0hDeAhoLX85ktAr5OysJlbyZixc4sFJQ3hBZbANt6shgAcLaizu51APhPYjoEAfgyKavLe4/Kqo3YlVECY33Tn4vzLdueic+3Z+LN39Ok58prTThhnSZ9f0wUAGB/o54RQRCk6dPVRjM+356JjzafavXrZJVUodZkgataiaevEGuovknOaTZ0d8TWE2fxx5ECWRcUZBghoh7jvphovH37aIzp49Ps6+E+bgjRu6LeImDrybMwWwQkHC2UXv8qKQv/23caeWXiRXT9oXw8+d1B6Zf1yuRsnCyqhJerC+6a1Acx/fzg56FBSZURO9KL7b5WZV09Hv56L77ZlYMvtjcsAJZeVIHskipU1dVj/SHxgql1UUIQgAO5ZTDUmHDFO1tx7QfbYDJbIAiC1D2/N/ucNKRgrLdIy9tnl1Th3mW7sfFYIf7vh0O44u0tKKkyoq+/B9QqBfbnlNkNXTS2/WQxPtx0EinZpS3Ofnn8v/sR89omHLTWtSzfkYmdp0rw5h9pdhdb21/20wYEAID0fbTJN9Qgt7QGSgUwb3IUAOB4fjkyzlZi7YE8KBTA0rvHIkQvhsjLBwcCaD6MnDpbids+ScLz647AUGPCkBAvLJs/Hh/eNQYAsDmtCIIgYOuJs9I+h043fA9S8wzSxb2s2oTNLQSew6cNePuPNLvhjfZ4+OsU3P5pMi6J/7PJOiE/7s/D18kNAdE2Uyb1TEP7DuaWQRCACF83xA4LBgCkFZRLa7OcqzZJ3/u/XT0YAPDzwTOtBoKj1l6owcFeuH50KHw9NMgrq8GGFoaw2qPGaMaSNYfx8Ncp+D7ldNs7dBOGESLqNRQKBa4fJf5FvjI5G/tyzqG40giVUgFA7CX5wNplf82IYKhVCvx88AwWfLMP2SVVeOuPEwCAxVcPht5NDReVUhqq+e2w/S/0t/5IQ2G52JuwKU280OWUVOOa97fjsjcTcc8Xu1BtNCPa3wPXjBDfY1/2OWxIzUdxZR1yS2twILcMp8/VoNg6rl9WbcKps5WoN1tw7QfbMPKlP/Dktwdw77LdKK40ItLPHVoXJUqqjFAogDdvG4Wrh4vv/XUzvSNJp0owf/luvPnHCdy8NAmTXtnYZAppea0Jm44XwVhvwft/nkRdvRmrd4s9NBW19UjKEHs6SquMOGftAZo6wB9A054RW73I8DA9hoZ4wUOjQl29BS/9fBSCAEwfGIAJ1roeALjMGkZ2pBfb3Vdo9e4cXPPeNqRkn4On1gUv3zAMPy+MwczBQZg5OBAalRKnz9Vg47Eiu0B0uFEYsX0/NCqldO4bSy+qxA0fbsd1H27H+5vS8eCXe1FtbH5tjhOFFbjmvW34aHO69HVsx1paZcSyHZlY8r/DAMQhwCe/O4Dnf0zFycIKWCyCVLycW1oj9YjZhmjG9fFBkJcrwrzdYBGAQ6fF5/MN4nH5e2owd1IfaFyUyCyuavUO1rZANSTEC65qFe65JBIA8OnWjDZ7Nf44UoDHvklBsvV823y4+STyymoQ5u0m/V+QA8MIEfUqd18SCYUC2HayGB8nit3a140MwcAgT1QbzThjEOtB3r5tND66ayw0LkokHC1E7DtbUVFXj1ER3rhjQh/p/WYMEi+YuxsVxabmGeyGMFLzxLqHtfvzYKy3wCI0FCPeOj4cYyPFnpx9Oeewdn+etN+2k8VN6gT2ZJ1DUkYJThSKQ0pr9+chq6Qa4T5u+P7Ryfh90TTcPDYc/5ozHGP7+OCeyeIFZ93BPLvhooyzlXh0ZQrqLQIGBemgd1OjuNKIxf87ZDfklHSqROox+fN4Ed7+4wRKGhVM2upYbL0iYd5u0jBNXlmN1JNjtgj42VpbMyHKF0qlQlqwbou192Keta02Q0O8EOzlihqTGUkZJag3W/DiulT8bc1h1NVbMHWAP35/chrmTY6CizVUuGtcMKmvGGhe+VVcVE0hZk0csvYOGapNWHdQ/D6/fMMwAMDmtLN2Q1Ev/XwEB08boFYpoHN1QV5ZDd7/Mx3nO1tRh/uW78HR/HK8nXACJwsr8JV1uvd1o0Lxn7ljoVAAvxzOx7H8cny4WRwaAsQhpIziKmlmFtDQe2E777afjdF9vAE0DNUUWoecgrxcoXNVS71Rvx5uuZfDNiRmK+ieNzkSWhclDp02SLU8NiWVdVIvzIodmXhkZQp+PVyAOz5NxtPfHURuaTXSiyrx6Vax1++F64bCXePS4tfubgwjRNSrRPi64zJrgPjT2jV/1fAQzJ8SLW2zYEY/uKpViB0WjFUPToK3uxp19RYoFcC/bhgu9aQA4sVCoQAyi6ukdTVeWJcKiyBejMZYLyJ/Hi/E2v3iX98PTY3G+EgfDAj0xG3jIzCuj62wttTuorAjvVi6+KhVCmmbX6zDO7OGBOKOCRGY3NcPX94/EYE6V0T5e+Ct20Zh7iTxwj4+0geDg3WoNVmkReFqTWY8+OVeGGpMGNPHG+sWxmDr/10GPw8N0osq7WpMtp0Ug4LtkD+xXnwusV7wE44WwGwRpGm9/QI9Eax3hVIhDiUVV9ahxmjGoytTsPFYERQK4Orh4rDDMOtFUTwvbpg+MNDuXCkUCswcIj73ceIpXPfhDnxpbdtfYwfiq/snNqkLAiCdX9tU2KuswxyHT4trdfyw7zRqTRYMDtbh9gkRGB3hDbNFwLoDYkAxVJukAtj1j0/F27eNBgB8vi0DJxr1PNSazHjoq71S74vZIuC5H1Olgub5U6JwzYgQzLb2fC1Zc1gKZLbv7fkzZo6cMcBktkgFzWOtPxu2f229KPnWot4QvSuAhu/phlT7YuV3N57A5W8l4kRhhdQzMjREvIWCn6cWt4wLBwD8J/EU1h86gye/PYBLX9uEcf/aiOEv/o6YVzfhH9aeqzF9vKFQAP/bdxpTX9+MG/+zAyazgJmDAxE7NKjJeXAkhhEi6nXuafQXuKtaiekDA3DjmDBE+3tgQKCntForIE4HXrNgCi4bFIB/XD8MI8L1du+ld1NjUJD4yz0l6xyyiquwL6cMLkoFnp89RKp7+HjLKWSVVMNNrcKiWQPxw4IpSHhqOvw9tRgUrIOHRoVakwWCAPS1zp44kFsmhYE5o8MAALsySqQx/vsvjcarN4/Efx++xG7WUGMKhQJ3TRKPxzam/9PBM8gorkKQlxaf3jMermoV9G5q/NW6MNy7G09IUz63WQtAn5w1UHpPtUqBd24fDS9XFxRXGpGSfQ4Z1gt/vwAPqFVKqe4j91wNHvpqLxKOFkLjosTSuWOlKdbDQhu+l3dPirQLeTa279+uzFIcyy+Hh0aFj+8eh4UzB0ChaLo90DC8Y/PQtL5QqxQ4V21CTmm11HMh9pIpcLP1gvzd3lwIgoBNaYWotwgYGOSJQcE6XDE0CLOGBKHeIuDZNYelWp5n1xzGgdwyeLursXz+BLgoFdidWYq6eguGhnhhrDWILpo1AEqFeD4tAqT1bnZlNIRPrXV20dEz5dibdQ4VdfXw89BgqLX3aGCQuI8tYNlmGAVbw8isIUFQqxQ4UVgp3TG52liPT7Zk4NTZKty/Yo80bDgouCEEPji1LxQKsQh14ar9WLs/z254zRa0/ho7EGsWTMH/FkzBlH5+UCrEYTqtixL/uG5Yi+fCURhGiKjXmT4gAJF+7uLHAwPgplHBTaNCwpPT8NsTU+GqVtlt3zfAE8vvmygVXZ5vYrR4cd2dVSqtZ3FJXz8Eerli5mDxL8bcUvGX+pXDguChte/OVikVUjc8IF48o/09xB4H6wyV+y+NhlIBnDHUoqzaBH9PLSZF+7XreK8fFQqNSolj+eU4csaAldbiyftiohGg00rb3TY+AsNCvVBRW49Xfj2O7JIqZJdUw0WpwH2XRkvB4JoRIQjRu2GW9a/hj7eckmav2EKRrcdi1a4cbE8vhqtaiZUPTMJVwxvqCmzBTuOixG3WmUnni+nvjwGBngjy0uKZKwdh++KZuMraC9CSaH8P6fz6eWgwOtwbg60X4Hc3nkR2STX0bmrcNDZM+v54aFQ4UViJP48V4fdUsaj5ymENX+cf1w+Fu0aFvdnn8MK6VHy3Nxdr9udBqQCWzh2HywYH2v18zJscKV2g+wfqcIM1TALAG7eOQoBOixqTWepFuc5ay3TkTDk2W2uMpg8KgNIa0KL8xICaU1INs0WQekaCvcQwondXI6a/WKtj6x3ZdLwINdZaG1vAiPJzh2ejn79ofw/cOEZsWx9fdzwyvS++fmAiDv8jFil/n4WvH5iI356YKoW/sX18sOqhS7Dr2Vl4/eaRWPXQJPSxfq/lxDBCRL2OUqnA364ajBC9Kx6c2ld63kWllGoPOsL2l/6eRmHkymHihXpIiE7qSgeAG8eGN/setqEajUqJa4aH4FLrhQUA/D21GBysk8b6AbHAtrmehOZ4u2twhTU4vPTzURw6bWg2AKiUCrxsXd/jf/tO4wXrgmNjI33gqXVB/E0jEHdZP/x99lDrMYoX603Hi3D6XA183NWYNUT8OuE+YhixDQ3dPSlSCm02Q0K88O8bh+OTe8bBx0PTbNtd1SokPDUdu56dhbjL+re43flsQzXTBooXdFvwsdXk3DWpj1TjoHdT4x5rkHhn4wmphqVxGAn3cccHd46BUgH8d3culqwRC1Kfjh2Eyf3EUPjE5QMQqheLTRuHD0DsWfL31OKmMWEYHeEtnV/bjJi51t6r9LOV0s/QzEY9PKHeblCrFDCaLcg31Eg1I8H6hmGqa6xBb/WeXBjrLVh/UAwlMwYFSMN8tjqdxl67eSR2/G0mtjwzA0uuHoKpAwKgc1XDz1OLqQMCmt0nQKfFbRMiMC7St8lrcmAYIaJe6eoRIUhacrnd7I3Ommh9j6NnyrHfOqZ/xVDxQqZQKKSLir+nFjH9mu/NiB0WDBelAreOD7f7KxewjdUrpHVSAEh1CO11y3gxBNlmeVw7MgS+zVzYx0X6YuFl/QE0FJZOs86OCfRyxTNXDpZ6U6YNCECgTgulQryYbnxqujRsEObTcJHUuCjx8LS+aM7cSZFScOhKi2YNQNxl/bD4KnHa68iwhiEhF6UC957Xy/Xg1Gi4qpU4cqYcNSYzwrzd7GpaAODyIUF4/loxiFkEMegsmN5Pel3vrkbCU9OR8NQ0uGnse9f6+Llj799n4e3bRwNomHEEAKF6V4yO8IaPuxpmi4DskmqolApMtRalAmJQjPAVeyCyS6qb1IwAwLWjQhCg0+L0uRp8ti1D6mF55spB+PecEfDUuuDakaFNvldqlRJh3m6yD7VcCPlKZ4mIeohgvSsifN2koZjREd7SRRkQaxM2HitE3GX9W+x5GR6mx/4XroCbdYhosnVc3iI0FC9OjPbFip1ZCNRppd6Y9po2IABBXlqpbsA2rbM5T1w+ADvSi6UZP5c2uig25qZRYf1fLoXZIkg1IjbhjcLIHRMiEOjlev7u3crbXYNnrhwsfd641ufakSF25wcQg+LcSZHSUv9XDA1q9uJ8X0w0jPUW7M8pw79vHC4No9icPwTXkkvtwqYPFAoFhoXqsd26Xs34SB/o3dR2+0T7eSDjbBUyi6ukmpGgRt9Xd40LFs0agOfWpuLNP9Kk+qOhIV4YFqrHrePDe3XgaA17RoiIALselsbd+4DYNb7r2Vkt1pzY6FzVUljRu6kxfWAAVEoFpg0UL1yxQ4Pwl5n98e7to9s9RGOjUipw4xixd2R4mJe0umlzXFRKvHfHGPh7atA3wAMjwvQtbhuoc20SRAAgwkf8K95FqcAjjXoP5DIwSAedqxgUHri0+V6aR6b1lZapP/8c2m03vR8+vmcc/Dy1LW7TlkAvV6nw2XYuGvfEzBzctLco0lo3cuSMQZp2e36oum18BPr6e0jTh68dGSIFkIs1iADsGSEiAiCGkTX7xHqE2GFdM83x/TvHoKTSiCjr7BoXlRJPxQ7q9Ps9dlk/1JstuGls238hR/i6I/GZy+CiVHQ4+ABiL87t4yMwuo93s9NvHU2tUmLFfRNQXlPfZEaUTaCXK5bOHYvskmpp6nJ3enb2EHy3N1eq3RnaRhiJ9hcDXnKGONSmc3WxK0YFxOP865WD8Ng3+wAA145qOixzMWIYISKCOCvHXaPC8FB9i9NsO0rnqobOVd32hu3k5arG3601D+1x/oWuI1xUSrx2y8hO798d2lNsefkQx62XMX1gAKYPbBgCmxDlC1e1En39PaWF4xqz9YzYpvcGtzD0dfXwYKmXZ6C19+VixzBCRARxtsO2/7usSeEiUXuFersh4cnp8NS6NNtzZbt7r835QzQ2CoUCS64Z0i1t7KkYRoiIrC6khoAIgDRjpjm26b0ms1gQEtJCGHFGLGAlIiJygMbTe4GWh2mcEcMIERGRg0T7NQzVBDczi8lZMYwQERE5SGSjMMJhmgYMI0RERA5im94LtFzA6owYRoiIiBykcc8Ia0YacDYNERGRgwwI8oRCAei0LvB277o1aHo7hhEiIiIHCdG74aO7xsLHXXNRL+/eUQwjREREDnRNB+/Y7AxYM0JERESy6lAYiY+Px4QJE6DT6RAYGIg5c+YgLS2t1X2OHDmCm2++GVFRUVAoFHj33XcvpL1ERER0kelQGNmyZQvi4uKQnJyMhIQEmEwmxMbGoqqqqsV9qqur0bdvX7z66qsIDm75ls5ERETknDpUM7Jhwwa7z1esWIHAwECkpKRg2rRpze4zYcIETJgwAQDwt7/9rZPNJCIioovVBRWwGgwGAICvb9u3de6Iuro61NXVSZ+Xl5d36fsTERFRz9HpAlaLxYJFixYhJiYGw4cP78o2IT4+Hnq9XnpERER06fsTERFRz9HpMBIXF4fU1FSsXr26K9sDAFiyZAkMBoP0yM3N7fKvQURERD1Dp4ZpFi5ciPXr12Pr1q0IDw/v6jZBq9VCq9V2+fsSERFRz9OhMCIIAh5//HGsXbsWiYmJiI6O7q52ERERkZPoUBiJi4vDqlWrsG7dOuh0OhQUFAAA9Ho93NzcAADz5s1DWFgY4uPjAQBGoxFHjx6VPs7Ly8OBAwfg6emJ/v37d+WxEBERUS+kEARBaPfGLayjv3z5csyfPx8AMGPGDERFRWHFihUAgKysrGZ7UKZPn47ExMR2fd3y8nLo9XoYDAZ4eXm1t7lEREQko/Zevzs8TNOW8wNGVFRUu/YjIiIi58R70xAREZGsesVde209K1z8jIiIqPewXbfbGiHpFWGkoqICALj4GRERUS9UUVEBvV7f4usdKmCVi8ViwZkzZ6DT6Vosou2M8vJyREREIDc396ItjOUx9n4X+/EBPMaLwcV+fMDFf4zdcXyCIKCiogKhoaFQKluuDOkVPSNKpbJbFlez8fLyuih/sBrjMfZ+F/vxATzGi8HFfnzAxX+MXX18rfWI2LCAlYiIiGTFMEJERESycuowotVq8eKLL17U98HhMfZ+F/vxATzGi8HFfnzAxX+Mch5fryhgJSIioouXU/eMEBERkfwYRoiIiEhWDCNEREQkK4YRIiIikpVTh5GPPvoIUVFRcHV1xaRJk7B79265m9Qp8fHxmDBhAnQ6HQIDAzFnzhykpaXZbTNjxgwoFAq7x6OPPipTizvuH//4R5P2Dx48WHq9trYWcXFx8PPzg6enJ26++WYUFhbK2OKOi4qKanKMCoUCcXFxAHrfOdy6dSuuu+46hIaGQqFQ4Mcff7R7XRAEvPDCCwgJCYGbmxtmzZqFkydP2m1TWlqKuXPnwsvLC97e3njggQdQWVnpwKNoXWvHaDKZsHjxYowYMQIeHh4IDQ3FvHnzcObMGbv3aO68v/rqqw4+kpa1dR7nz5/fpP1XXXWV3TY9+Ty2dXzN/Z9UKBR44403pG168jlsz/WhPb8/c3JyMHv2bLi7uyMwMBDPPPMM6uvru6ydThtGvv32Wzz11FN48cUXsW/fPowaNQpXXnklioqK5G5ah23ZsgVxcXFITk5GQkICTCYTYmNjUVVVZbfdQw89hPz8fOnx+uuvy9Tizhk2bJhd+7dv3y699uSTT+Lnn3/G999/jy1btuDMmTO46aabZGxtx+3Zs8fu+BISEgAAt956q7RNbzqHVVVVGDVqFD766KNmX3/99dfx/vvv4+OPP8auXbvg4eGBK6+8ErW1tdI2c+fOxZEjR5CQkID169dj69atePjhhx11CG1q7Rirq6uxb98+PP/889i3bx/WrFmDtLQ0XH/99U22ffnll+3O6+OPP+6I5rdLW+cRAK666iq79v/3v/+1e70nn8e2jq/xceXn52PZsmVQKBS4+eab7bbrqeewPdeHtn5/ms1mzJ49G0ajETt37sSXX36JFStW4IUXXui6hgpOauLEiUJcXJz0udlsFkJDQ4X4+HgZW9U1ioqKBADCli1bpOemT58uPPHEE/I16gK9+OKLwqhRo5p9raysTFCr1cL3338vPXfs2DEBgJCUlOSgFna9J554QujXr59gsVgEQejd5xCAsHbtWulzi8UiBAcHC2+88Yb0XFlZmaDVaoX//ve/giAIwtGjRwUAwp49e6RtfvvtN0GhUAh5eXkOa3t7nX+Mzdm9e7cAQMjOzpaei4yMFN55553ubVwXae4Y7733XuGGG25ocZ/edB7bcw5vuOEGYebMmXbP9aZzeP71oT2/P3/99VdBqVQKBQUF0jZLly4VvLy8hLq6ui5pl1P2jBiNRqSkpGDWrFnSc0qlErNmzUJSUpKMLesaBoMBAODr62v3/DfffAN/f38MHz4cS5YsQXV1tRzN67STJ08iNDQUffv2xdy5c5GTkwMASElJgclksjufgwcPRp8+fXrt+TQajVi5ciXuv/9+u5tD9vZzaJOZmYmCggK7c6bX6zFp0iTpnCUlJcHb2xvjx4+Xtpk1axaUSiV27drl8DZ3BYPBAIVCAW9vb7vnX331Vfj5+WHMmDF44403urT72xESExMRGBiIQYMGYcGCBSgpKZFeu5jOY2FhIX755Rc88MADTV7rLefw/OtDe35/JiUlYcSIEQgKCpK2ufLKK1FeXo4jR450Sbt6xY3yulpxcTHMZrPdNxYAgoKCcPz4cZla1TUsFgsWLVqEmJgYDB8+XHr+rrvuQmRkJEJDQ3Ho0CEsXrwYaWlpWLNmjYytbb9JkyZhxYoVGDRoEPLz8/HSSy9h6tSpSE1NRUFBATQaTZNf8EFBQSgoKJCnwRfoxx9/RFlZGebPny8919vPYWO289Lc/0HbawUFBQgMDLR73cXFBb6+vr3yvNbW1mLx4sW488477W5C9pe//AVjx46Fr68vdu7ciSVLliA/Px9vv/22jK1tv6uuugo33XQToqOjcerUKTz77LO4+uqrkZSUBJVKdVGdxy+//BI6na7JEHBvOYfNXR/a8/uzoKCg2f+rtte6glOGkYtZXFwcUlNT7eopANiNz44YMQIhISG4/PLLcerUKfTr18/Rzeywq6++Wvp45MiRmDRpEiIjI/Hdd9/Bzc1NxpZ1jy+++AJXX301QkNDped6+zl0ZiaTCbfddhsEQcDSpUvtXnvqqaekj0eOHAmNRoNHHnkE8fHxvWLZ8TvuuEP6eMSIERg5ciT69euHxMREXH755TK2rOstW7YMc+fOhaurq93zveUctnR96AmccpjG398fKpWqSbVwYWEhgoODZWrVhVu4cCHWr1+PzZs3Izw8vNVtJ02aBABIT093RNO6nLe3NwYOHIj09HQEBwfDaDSirKzMbpveej6zs7OxceNGPPjgg61u15vPoe28tPZ/MDg4uElBeX19PUpLS3vVebUFkezsbCQkJLR5a/ZJkyahvr4eWVlZjmlgF+vbty/8/f2ln8uL5Txu27YNaWlpbf6/BHrmOWzp+tCe35/BwcHN/l+1vdYVnDKMaDQajBs3Dn/++af0nMViwZ9//onJkyfL2LLOEQQBCxcuxNq1a7Fp0yZER0e3uc+BAwcAACEhId3cuu5RWVmJU6dOISQkBOPGjYNarbY7n2lpacjJyemV53P58uUIDAzE7NmzW92uN5/D6OhoBAcH252z8vJy7Nq1SzpnkydPRllZGVJSUqRtNm3aBIvFIgWxns4WRE6ePImNGzfCz8+vzX0OHDgApVLZZGijtzh9+jRKSkqkn8uL4TwCYm/luHHjMGrUqDa37UnnsK3rQ3t+f06ePBmHDx+2C5W2YD106NAua6hTWr16taDVaoUVK1YIR48eFR5++GHB29vbrlq4t1iwYIGg1+uFxMREIT8/X3pUV1cLgiAI6enpwssvvyzs3btXyMzMFNatWyf07dtXmDZtmswtb7+nn35aSExMFDIzM4UdO3YIs2bNEvz9/YWioiJBEATh0UcfFfr06SNs2rRJ2Lt3rzB58mRh8uTJMre648xms9CnTx9h8eLFds/3xnNYUVEh7N+/X9i/f78AQHj77beF/fv3SzNJXn31VcHb21tYt26dcOjQIeGGG24QoqOjhZqaGuk9rrrqKmHMmDHCrl27hO3btwsDBgwQ7rzzTrkOqYnWjtFoNArXX3+9EB4eLhw4cMDu/6ZtBsLOnTuFd955Rzhw4IBw6tQpYeXKlUJAQIAwb948mY+sQWvHWFFRIfz1r38VkpKShMzMTGHjxo3C2LFjhQEDBgi1tbXSe/Tk89jWz6kgCILBYBDc3d2FpUuXNtm/p5/Dtq4PgtD278/6+nph+PDhQmxsrHDgwAFhw4YNQkBAgLBkyZIua6fThhFBEIQPPvhA6NOnj6DRaISJEycKycnJcjepUwA0+1i+fLkgCIKQk5MjTJs2TfD19RW0Wq3Qv39/4ZlnnhEMBoO8De+A22+/XQgJCRE0Go0QFhYm3H777UJ6err0ek1NjfDYY48JPj4+gru7u3DjjTcK+fn5Mra4c37//XcBgJCWlmb3fG88h5s3b2725/Lee+8VBEGc3vv8888LQUFBglarFS6//PImx11SUiLceeedgqenp+Dl5SXcd999QkVFhQxH07zWjjEzM7PF/5ubN28WBEEQUlJShEmTJgl6vV5wdXUVhgwZIrzyyit2F3K5tXaM1dXVQmxsrBAQECCo1WohMjJSeOihh5r8UdeTz2NbP6eCIAiffPKJ4ObmJpSVlTXZv6efw7auD4LQvt+fWVlZwtVXXy24ubkJ/v7+wtNPPy2YTKYua6fC2lgiIiIiWThlzQgRERH1HAwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyer/AZ6retlI2L7vAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in layers:\n",
        "    if isinstance(layer, BatchNorm1d):\n",
        "        layer.training = False\n",
        "\n",
        "with torch.no_grad():\n",
        "    emb = C[Xtr]\n",
        "    x = emb.view(Xtr.shape[0], -1)\n",
        "    for layer in layers:\n",
        "        x = layer(x)\n",
        "    loss = F.cross_entropy(x, Ytr)\n",
        "    print(f\"Training loss: {loss}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    emb = C[Xval]\n",
        "    x = emb.view(Xval.shape[0], -1)\n",
        "    for layer in layers:\n",
        "        x = layer(x)\n",
        "    loss = F.cross_entropy(x, Yval)\n",
        "    print(f\"Validation loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LijCwilkv_-y",
        "outputId": "4497a612-d41d-4aa8-e8fc-5216aaf81125"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.1061084270477295\n",
            "Validation loss: 2.1458516120910645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in layers:\n",
        "    if isinstance(layer, BatchNorm1d):\n",
        "        layer.training = False\n",
        "\n",
        "for _ in range(10):\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "        emb = C[torch.tensor([context])]\n",
        "        x = emb.view(emb.shape[0], -1)\n",
        "        for layer in layers:\n",
        "            x = layer(x)\n",
        "        probs = F.softmax(x, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
        "        out.append(itos[ix])\n",
        "        context = context[1:] + [ix]\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "    print(\"\".join(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85EW1Ca7wWyF",
        "outputId": "c97429af-01bf-446f-aecf-0f979ea3605b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raya.\n",
            "ava.\n",
            "ajah.\n",
            "ila.\n",
            "zaditcondi.\n",
            "lyn.\n",
            "hadeno.\n",
            "aso.\n",
            "moan.\n",
            "asharramilaiah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Further Modularization"
      ],
      "metadata": {
        "id": "xm2yecBuCu5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Introduce Embedding, Flatten, and Sequential layers to further modularize the code.\n",
        "# 2. Initialize the network using these layers.\n",
        "# 3. Train the model, evaluate, and generate samples.\n",
        "# 4. (Optional) Experiment with scaling the network and adjusting hyperparameters."
      ],
      "metadata": {
        "id": "O_wsGwv3CwcR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding:\n",
        "\n",
        "    def __init__(self, num_embeddings, embedding_dim):\n",
        "        self.weight = torch.randn(num_embeddings, embedding_dim)\n",
        "\n",
        "    def __call__(self, IX):\n",
        "        return self.weight[IX]\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "class Sequential:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def parameters(self):\n",
        "        return [p for layer in self.layers for p in layer.parameters()]\n",
        "\n",
        "class Flatten:\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, T, C = x.shape\n",
        "        out = x.view(B, T * C)\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "fGfAsHx0xvzU"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(block_size * n_embd, n_hidden, bias=False),\n",
        "    BatchNorm1d(n_hidden),\n",
        "    Tanh(),\n",
        "    Linear(n_hidden, vocab_size, bias=False),\n",
        "    BatchNorm1d(vocab_size)\n",
        "])\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].gamma *= 0.1\n",
        "\n",
        "print(f\"Number of parameters: {sum(p.nelement() for p in model.parameters())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsToJMSMzeQ4",
        "outputId": "9d347c84-fec3-46a8-fff0-57ff79d679dd"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 6224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "AvM24qN703gz"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "max_steps = 200000\n",
        "print_steps = 10000\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "    ix = torch.randint(n, (batch_size, ))\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    if i % print_steps == 0:\n",
        "        print(f\"step: {i}, loss: {loss}\")\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    lr = 0.1 if i < 100000 else 0.01\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    stepi.append(i)\n",
        "    lossi.append(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUA8qjTC0-Pe",
        "outputId": "0fb88d62-2758-4a86-eac4-1545c8a6b0bf"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss: 3.2949705123901367\n",
            "step: 10000, loss: 2.3530542850494385\n",
            "step: 20000, loss: 2.2018027305603027\n",
            "step: 30000, loss: 2.3210504055023193\n",
            "step: 40000, loss: 2.317556381225586\n",
            "step: 50000, loss: 2.086444616317749\n",
            "step: 60000, loss: 2.113703489303589\n",
            "step: 70000, loss: 2.3107290267944336\n",
            "step: 80000, loss: 1.9710311889648438\n",
            "step: 90000, loss: 1.955386996269226\n",
            "step: 100000, loss: 2.3803508281707764\n",
            "step: 110000, loss: 2.084139585494995\n",
            "step: 120000, loss: 2.0261926651000977\n",
            "step: 130000, loss: 2.247983694076538\n",
            "step: 140000, loss: 2.200082302093506\n",
            "step: 150000, loss: 2.2982263565063477\n",
            "step: 160000, loss: 2.290942430496216\n",
            "step: 170000, loss: 1.8327735662460327\n",
            "step: 180000, loss: 2.0207483768463135\n",
            "step: 190000, loss: 2.262930393218994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    if isinstance(layer, BatchNorm1d):\n",
        "        layer.training = False\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(Xtr)\n",
        "    loss = F.cross_entropy(logits, Ytr)\n",
        "    print(f\"Training loss: {loss}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(Xval)\n",
        "    loss = F.cross_entropy(logits, Yval)\n",
        "    print(f\"Validation loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbtAyUJt3q54",
        "outputId": "0a71e22e-a65e-4ac9-f7e6-403f971cbec3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.1121103763580322\n",
            "Validation loss: 2.154146194458008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
        "        out.append(itos[ix])\n",
        "        context = context[1:] + [ix]\n",
        "        if ix ==0:\n",
        "            break\n",
        "\n",
        "    print(\"\".join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBMH-uJc383j",
        "outputId": "fd720e60-afae-4354-9d7e-98d858da3efc"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roviyah.\n",
            "siaena.\n",
            "jkene.\n",
            "skyn.\n",
            "cazritzz.\n",
            "albiel.\n",
            "dura.\n",
            "kaslla.\n",
            "zaquis.\n",
            "sica.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. (Optional) Experiment with scaling the network and adjusting hyperparameters.\n",
        "\n",
        "block_size = 8\n",
        "\n",
        "def build_dataset(words):\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for w in words:\n",
        "        context = [0] * block_size\n",
        "        for ch in w + '.':\n",
        "            ix = stoi[ch]\n",
        "            X.append(context)\n",
        "            Y.append(ix)\n",
        "            context = context[1:] + [ix]\n",
        "\n",
        "    X = torch.tensor(X)\n",
        "    Y = torch.tensor(Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(words)\n",
        "\n",
        "n1 = int(len(words) * 0.8)\n",
        "n2 = int(len(words) * 0.9)\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xval, Yval = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])\n",
        "\n",
        "n = len(Xtr)\n",
        "\n",
        "print(len(Xtr), len(Xval), len(Xte))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxwZbC7NChbf",
        "outputId": "de5f1dba-fd39-4120-b223-eb57ec4debf3"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182421 22829 22896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 24\n",
        "n_hidden = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, n_embd),\n",
        "    Flatten(),\n",
        "    Linear(block_size * n_embd, n_hidden, bias=False),BatchNorm1d(n_hidden),Tanh(),\n",
        "    Linear(n_hidden, n_hidden, bias=False),BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "    Linear(n_hidden, vocab_size, bias=False),\n",
        "    BatchNorm1d(vocab_size)\n",
        "])\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.layers[-1].gamma *= 0.1\n",
        "\n",
        "print(f\"Number of parameters: {sum(p.nelement() for p in model.parameters())}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0oBcgj3J7Eb",
        "outputId": "bb87b4e3-6e7e-451b-8ae3-08729a7afb08"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 23294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lossi = []\n",
        "\n",
        "batch_size = 32\n",
        "max_steps = 200000\n",
        "print_steps = 10000\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "    ix = torch.randint(n, (batch_size, ))\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "    logits = model(Xb)\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    if i % print_steps == 0:\n",
        "        print(f\"step: {i}, loss: {loss}\")\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    lr = 0.1 if i < 100000 else 0.01\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.data += -lr * p.grad\n",
        "\n",
        "    stepi.append(i)\n",
        "    lossi.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-QRmBOyKIp4",
        "outputId": "1c6be61e-217a-4f64-967a-db7ecd1c94a3"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss: 3.2958295345306396\n",
            "step: 10000, loss: 2.1692700386047363\n",
            "step: 20000, loss: 1.9554200172424316\n",
            "step: 30000, loss: 2.1338343620300293\n",
            "step: 40000, loss: 1.9819382429122925\n",
            "step: 50000, loss: 2.1684625148773193\n",
            "step: 60000, loss: 1.9362094402313232\n",
            "step: 70000, loss: 2.2136826515197754\n",
            "step: 80000, loss: 1.9798575639724731\n",
            "step: 90000, loss: 2.03904390335083\n",
            "step: 100000, loss: 1.9013460874557495\n",
            "step: 110000, loss: 2.1326072216033936\n",
            "step: 120000, loss: 1.8140379190444946\n",
            "step: 130000, loss: 2.0207772254943848\n",
            "step: 140000, loss: 1.9931190013885498\n",
            "step: 150000, loss: 1.4671200513839722\n",
            "step: 160000, loss: 2.0358757972717285\n",
            "step: 170000, loss: 1.9971435070037842\n",
            "step: 180000, loss: 1.8163961172103882\n",
            "step: 190000, loss: 2.146852970123291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    if isinstance(layer, BatchNorm1d):\n",
        "        layer.training = False\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(Xtr)\n",
        "    loss = F.cross_entropy(logits, Ytr)\n",
        "    print(f\"Training loss: {loss}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(Xval)\n",
        "    loss = F.cross_entropy(logits, Yval)\n",
        "    print(f\"Validation loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmvFL8SCKPas",
        "outputId": "3a36cbac-ccb9-4f78-d435-b13677b8d574"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.9325993061065674\n",
            "Validation loss: 2.0268492698669434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "        logits = model(torch.tensor([context]))\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        ix = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
        "        out.append(itos[ix])\n",
        "        context = context[1:] + [ix]\n",
        "        if ix ==0:\n",
        "            break\n",
        "\n",
        "    print(\"\".join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQTHRPqyKTIG",
        "outputId": "5c5dd53d-68d8-4a4c-9fe6-247db16db48c"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jamethyn.\n",
            "alan.\n",
            "kourtte.\n",
            "raklainea.\n",
            "riklynn.\n",
            "brylee.\n",
            "josee.\n",
            "laydon.\n",
            "hawan.\n",
            "vaydna.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Notes\n",
        "\n"
      ],
      "metadata": {
        "id": "rFGiFpuoBkHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to copy and paste multiple text cells and code cells together in Google Colab\n",
        "\n",
        "   - You can use `Ctrl` or `Cmd` in combination with arrow keys to select multiple cells quickly.\n",
        "   - After selecting, use `Ctrl + C` or `Cmd + C` to copy and `Ctrl + V` or `Cmd + V` to paste.\n",
        "   - Tip: This cell selection can also be used for moving groups of cells up and down the colab.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Olv9l3QHBnlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tidying up the noisy loss graph\n",
        "\n",
        "`plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))`\n",
        "\n",
        "This code snippet seems to be using the `matplotlib.pyplot` library (aliased as `plt`) to plot the moving average of a loss value over time. Let's break down the code step-by-step:\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "* **`lossi`:** This is assumed to be a Python list or a 1-dimensional NumPy array containing loss values collected during the training of a machine learning model.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "1. **`torch.tensor(lossi)`:** This part converts the `lossi` list or array into a PyTorch tensor. PyTorch tensors are preferred for numerical operations in deep learning due to their GPU acceleration capabilities.\n",
        "\n",
        "2. **`.view(-1, 1000)`:** This reshapes the tensor. Let's break it down:\n",
        "   - `.view()` is a PyTorch tensor method for reshaping tensors.\n",
        "   - `-1` is a placeholder. PyTorch will infer the appropriate size for this dimension based on the other dimension and the total number of elements.\n",
        "   - `1000` specifies that the second dimension should have a size of 1000.\n",
        "   - In essence, this line is trying to reshape the loss tensor into a matrix where each row contains 1000 loss values. If `lossi` doesn't have a multiple of 1000 elements, you might run into errors.\n",
        "\n",
        "3. **`.mean(1)`:** This calculates the mean along the second dimension (axis 1 in Python's zero-based indexing) of the reshaped tensor.  Since each row now represents a group of 1000 loss values, this operation effectively computes the average loss for every 1000 steps.\n",
        "\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "The primary goal of this code is to visualize the trend of the training loss over time. By calculating the moving average over windows of 1000 steps, the plot becomes less noisy and reveals the overall convergence behavior of the model during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "eIkhVPU-im_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving Average: Smoothing Out the Noise\n",
        "\n",
        "In Machine Learning you often deal with noisy data. A moving average is a simple yet powerful tool to smooth out fluctuations and highlight trends in data.  Imagine sliding a window of a fixed size over a dataset, calculating the average of the values within the window at each step. This \"moving\" average helps visualize the underlying pattern by reducing the impact of short-term fluctuations.\n",
        "\n",
        "**Here's how it works:**\n",
        "\n",
        "1. **Choose a window size (k):** This determines how many data points are considered for each average. Larger windows result in smoother curves but might mask important short-term variations.\n",
        "2. **Slide the window:** Move the window one step at a time across your data.\n",
        "3. **Calculate the average:** For each position of the window, calculate the average of the data points within it. This becomes the moving average value for that point.\n",
        "\n",
        "**Scenarios in Machine Learning where Moving Averages are useful:**\n",
        "\n",
        "**1. Time Series Analysis & Forecasting:**\n",
        "\n",
        "   - **Smoothing noisy data:** In financial markets or weather forecasting, moving averages help identify trends in stock prices or temperature fluctuations, respectively.\n",
        "\n",
        "   ```python\n",
        "   import torch\n",
        "\n",
        "   data = torch.tensor([2, 4, 3, 7, 5, 8, 6, 9, 7, 10]) # Example data\n",
        "   window_size = 3\n",
        "\n",
        "   def moving_average(data, window_size):\n",
        "     \"\"\"Calculates the moving average of the data.\"\"\"\n",
        "     cumsum = [0]\n",
        "     for i, x in enumerate(data, 1):\n",
        "         cumsum.append(cumsum[i-1] + x)\n",
        "     return torch.tensor([(cumsum[i] - cumsum[i-window_size])/window_size for i in range(window_size, len(data)+1)])\n",
        "\n",
        "   smoothed_data = moving_average(data, window_size)\n",
        "   print(f\"Original data: {data}\")\n",
        "   print(f\"Smoothed data: {smoothed_data}\")\n",
        "   ```\n",
        "\n",
        "   - **Feature Engineering:** Moving averages can create new features that capture short-term or long-term trends in data. For example, a 5-day moving average of stock prices can be a useful feature for predicting future stock movements.\n",
        "\n",
        "**2. Deep Learning:**\n",
        "\n",
        "   - **Optimizing Training:**  The Exponential Moving Average (EMA) of gradients is used in optimizers like Adam and RMSprop to stabilize and accelerate training convergence.\n",
        "\n",
        "   ```python\n",
        "   # Using EMA in optimizer\n",
        "   optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "   ```\n",
        "\n",
        "   - **Evaluating Model Performance:** Moving averages can smooth out noisy validation loss curves during training, making it easier to track the learning progress.\n",
        "\n",
        "**3. Anomaly Detection:**\n",
        "\n",
        "   - By comparing the original data points with their moving averages, significant deviations can signal potential anomalies. This is helpful in fraud detection or system monitoring.\n",
        "\n",
        "**Different Types of Moving Averages:**\n",
        "\n",
        "* **Simple Moving Average (SMA):** Gives equal weight to all data points within the window.\n",
        "* **Exponential Moving Average (EMA):** Assigns higher weights to more recent data points, making it more responsive to recent changes.\n",
        "* **Cumulative Moving Average (CMA):**  Calculates the average of all data points up to the current point, constantly evolving.\n",
        "\n",
        "**Choosing the Right Window Size:**\n",
        "\n",
        "The optimal window size depends on the specific application and the data's characteristics.  Smaller windows are more sensitive to recent changes but might be susceptible to noise. Larger windows offer smoother curves but might lag behind rapid fluctuations.\n",
        "\n",
        "By understanding the concept of moving averages and their applications in various Machine Learning scenarios, you can effectively utilize this simple yet powerful tool to gain valuable insights from your data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lhU0BUyHAb3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Normalization and Exponential Moving Average\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "  bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
        "  bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
        "\n",
        "with torch.no_grad():\n",
        "  self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "  self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "While those code snippets resemble the moving average calculation, they are specifically implementing the **Exponential Moving Average (EMA)**, a close relative.\n",
        "\n",
        "Here's why:\n",
        "\n",
        "* **Weighting Scheme:**  A simple moving average gives equal weight to all points within the window. In contrast, EMA applies exponentially decreasing weights as we move further back in time. The code reflects this by giving a weight of `0.999` to the previous average (`bnmean_running`, `bnstd_running`, `self.running_mean`, `self.running_var`) and a much smaller weight of `0.001` to the current value (`bnmeani`, `bnstdi`, `xmean`, `xvar`).\n",
        "\n",
        "* **Recursive Calculation:** Instead of averaging over a fixed window, EMAs are calculated recursively. The current EMA depends on the previous EMA and the current data point.  This recursive nature is evident in the code (`running_mean = ...`, `running_var = ...`).\n",
        "\n",
        "**In Essence:**\n",
        "\n",
        "Both examples you provided are indeed using a form of moving average, but specifically the Exponential Moving Average (EMA), which is particularly valuable in:\n",
        "\n",
        "* **Batch Normalization:** The first snippet likely comes from a Batch Normalization layer implementation, where `bnmean_running` and `bnstd_running` are the running estimates of the batch mean and standard deviation, respectively.\n",
        "* **Optimizer Updates:** The second snippet could be part of an optimizer like Adam or RMSprop, using EMA to calculate running averages of gradient moments, which helps smooth the optimization process.\n",
        "\n",
        "**Key Takeaway:**\n",
        "\n",
        "While all EMAs are moving averages, not all moving averages are EMAs. The key difference lies in the weighting scheme and the recursive calculation.\n"
      ],
      "metadata": {
        "id": "EJNCdpqmHtxK"
      }
    }
  ]
}